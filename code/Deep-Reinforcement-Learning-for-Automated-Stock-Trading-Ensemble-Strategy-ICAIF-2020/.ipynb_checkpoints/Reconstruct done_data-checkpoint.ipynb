{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8265465b-e0f6-4a46-a051-ffb27010e3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# common library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "#from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "#from tensorflow.python.compiler import tensorrt as trt\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "# preprocessor\n",
    "from preprocessing.preprocessors import *\n",
    "# config\n",
    "from config.config import *\n",
    "# model\n",
    "from model.models import *\n",
    "import pandas\n",
    "import os\n",
    "import datetime as dt\n",
    "import yfinance\n",
    "import pandas as pd\n",
    "from ta import add_all_ta_features\n",
    "from ta.utils import dropna\n",
    "import pandas_market_calendars as mcal\n",
    "\n",
    "# Commodity Channel Index Python Code\n",
    "# Load the necessary libraries\n",
    "from pandas_datareader import data as pdr\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance\n",
    "import pandas as pd\n",
    "\n",
    "# read and preprocess data\n",
    "preprocessed_path = \"done_data.csv\"\n",
    "if os.path.exists(preprocessed_path):\n",
    "    data = pd.read_csv(preprocessed_path, index_col=0)\n",
    "else:\n",
    "    data = preprocess_data()\n",
    "    data = add_turbulence(data)\n",
    "    data.to_csv(preprocessed_path)\n",
    "\n",
    "print(data.head())\n",
    "print(data.size)\n",
    "\n",
    "# 2015/10/01 is the date that validation starts\n",
    "# 2016/01/01 is the date that real trading starts\n",
    "# unique_trade_date needs to start from 2015/10/01 for validation purpose\n",
    "unique_trade_date = data[(data.datadate > 20151001)&(data.datadate <= 20200707)].datadate.unique()\n",
    "print(unique_trade_date)\n",
    "\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be85253-9f7b-4013-ba0e-e026d28dcf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rsi(df, periods = 14, ema = True):\n",
    "    \"\"\"\n",
    "    Returns a pd.Series with the relative strength index.\n",
    "    \"\"\"\n",
    "    close_delta = df.diff()\n",
    "\n",
    "    # Make two series: one for lower closes and one for higher closes\n",
    "    up = close_delta.clip(lower=0)\n",
    "    down = -1 * close_delta.clip(upper=0)\n",
    "    \n",
    "    if ema == True:\n",
    "\t    # Use exponential moving average\n",
    "        ma_up = up.ewm(com = periods - 1, adjust=True, min_periods = periods).mean()\n",
    "        ma_down = down.ewm(com = periods - 1, adjust=True, min_periods = periods).mean()\n",
    "    else:\n",
    "        # Use simple moving average\n",
    "        ma_up = up.rolling(window = periods, adjust=False).mean()\n",
    "        ma_down = down.rolling(window = periods, adjust=False).mean()\n",
    "        \n",
    "    rsi = ma_up / ma_down\n",
    "    rsi = 100 - (100/(1 + rsi))\n",
    "    return rsi\n",
    "\n",
    "# Commodity Channel Index \n",
    "def CCI(df, ndays): \n",
    "    df['TP'] = (df['High'] + df['Low'] + df['Close']) / 3 \n",
    "    df['sma'] = df['TP'].rolling(ndays).mean()\n",
    "    df['mad'] = df['TP'].rolling(ndays).apply(lambda x: pd.Series(x).mad())\n",
    "    df['CCI'] = (df['TP'] - df['sma']) / (0.015 * df['mad']) \n",
    "    return df\n",
    "\n",
    "def get_adx(high, low, close, lookback):\n",
    "    plus_dm = high.diff()\n",
    "    minus_dm = low.diff()\n",
    "    plus_dm[plus_dm < 0] = 0\n",
    "    minus_dm[minus_dm > 0] = 0\n",
    "    \n",
    "    tr1 = pd.DataFrame(high - low)\n",
    "    tr2 = pd.DataFrame(abs(high - close.shift(1)))\n",
    "    tr3 = pd.DataFrame(abs(low - close.shift(1)))\n",
    "    frames = [tr1, tr2, tr3]\n",
    "    tr = pd.concat(frames, axis = 1, join = 'inner').max(axis = 1)\n",
    "    atr = tr.rolling(lookback).mean()\n",
    "    \n",
    "    plus_di = 100 * (plus_dm.ewm(alpha = 1/lookback).mean() / atr)\n",
    "    minus_di = abs(100 * (minus_dm.ewm(alpha = 1/lookback).mean() / atr))\n",
    "    dx = (abs(plus_di - minus_di) / abs(plus_di + minus_di)) * 100\n",
    "    adx = ((dx.shift(1) * (lookback - 1)) + dx) / lookback\n",
    "    adx_smooth = adx.ewm(alpha = 1/lookback).mean()\n",
    "    return plus_di, minus_di, adx_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8965d19-f3a4-4176-9463-3cb72acbd92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(data).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95e7733-72f4-489e-85da-901cf9387bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADX(data: pd.DataFrame, period: int):\n",
    "    \"\"\"\n",
    "    Computes the ADX indicator.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = data.copy()\n",
    "    alpha = 1/period\n",
    "\n",
    "    # TR\n",
    "    df['H-L'] = df['High'] - df['Low']\n",
    "    df['H-C'] = np.abs(df['High'] - df['Close'].shift(1))\n",
    "    df['L-C'] = np.abs(df['Low'] - df['Close'].shift(1))\n",
    "    df['TR'] = df[['H-L', 'H-C', 'L-C']].max(axis=1)\n",
    "    del df['H-L'], df['H-C'], df['L-C']\n",
    "\n",
    "    # ATR\n",
    "    df['ATR'] = df['TR'].ewm(alpha=alpha, adjust=False).mean()\n",
    "\n",
    "    # +-DX\n",
    "    df['H-pH'] = df['High'] - df['High'].shift(1)\n",
    "    df['pL-L'] = df['Low'].shift(1) - df['Low']\n",
    "    df['+DX'] = np.where(\n",
    "        (df['H-pH'] > df['pL-L']) & (df['H-pH']>0),\n",
    "        df['H-pH'],\n",
    "        0.0\n",
    "    )\n",
    "    df['-DX'] = np.where(\n",
    "        (df['H-pH'] < df['pL-L']) & (df['pL-L']>0),\n",
    "        df['pL-L'],\n",
    "        0.0\n",
    "    )\n",
    "    del df['H-pH'], df['pL-L']\n",
    "\n",
    "    # +- DMI\n",
    "    df['S+DM'] = df['+DX'].ewm(alpha=alpha, adjust=False).mean()\n",
    "    df['S-DM'] = df['-DX'].ewm(alpha=alpha, adjust=False).mean()\n",
    "    df['+DMI'] = (df['S+DM']/df['ATR'])*100\n",
    "    df['-DMI'] = (df['S-DM']/df['ATR'])*100\n",
    "    del df['S+DM'], df['S-DM']\n",
    "\n",
    "    # ADX\n",
    "    df['DX'] = (np.abs(df['+DMI'] - df['-DMI'])/(df['+DMI'] + df['-DMI']))*100\n",
    "    df['ADX'] = df['DX'].ewm(alpha=alpha, adjust=False).mean()\n",
    "    del df['DX'], df['ATR'], df['TR'], df['-DX'], df['+DX'], df['+DMI'], df['-DMI']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd3f1a6-785c-44dd-be29-d166b750c016",
   "metadata": {},
   "outputs": [],
   "source": [
    "#20151001)&(data.datadate <= 20200707\n",
    "validation_start = \"2015-10-01\"\n",
    "trading_start = datetime.datetime.strptime(\"2016/01/01\", '%Y/%m/%d').strftime('%Y-%m-%d')\n",
    "end_trade_date = \"2020-07-07\"\n",
    "#data_.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc721aa9-a077-4d31-be05-d2b28d584b82",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#srm.MahalanobisDist(Returns=MD_input)[17:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79012d7-0fb3-4d47-b748-e224ef23c376",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import DM.systemicRiskMeasures1 as srm\n",
    "#SRM_mahalanobis_turbulent_nonturbulent_days= srm.MahalanobisDist_Turbulent_Returns(MD_returns=data_[['Close']].pct_change() , Returns=data_[['Close']].pct_change())\n",
    "#SRM_mahalanobis_turbulent_nonturbulent_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ac4afb-b476-4e7f-a168-858ecd9cb045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d363ee47-1b05-48dc-86cb-f0cc4a64db50",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.DataFrame(data.datadate.unique())\n",
    "\n",
    "start_ = datetime.datetime.strptime(str(dates.iloc[0].values[0]), '%Y%m%d').strftime('%Y-%m-%d')\n",
    "end_ = datetime.datetime.strptime(str(dates.iloc[-1].values[0]), '%Y%m%d').strftime('%Y-%m-%d')\n",
    "print(start_)\n",
    "print(validation_start)\n",
    "print(trading_start)\n",
    "print(end_trade_date)\n",
    "print(end_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26041f8a-4642-4e7e-9339-9e073fe7e8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_turbulence(df):\n",
    "    \"\"\"\n",
    "    add turbulence index from a precalcualted dataframe\n",
    "    :param data: (df) pandas dataframe\n",
    "    :return: (df) pandas dataframe\n",
    "    \"\"\"\n",
    "    turbulence_index = calculate_turbulence(df)\n",
    "    df = df.merge(turbulence_index, on='datadate')\n",
    "    df = df.sort_values(['datadate','tic']).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def calculate_turbulence(df):\n",
    "    \"\"\"calculate turbulence index based on dow 30\"\"\"\n",
    "    # can add other market assets\n",
    "    \n",
    "    df_price_pivot=df.pivot(index='datadate', columns='tic', values='adjcp')\n",
    "    unique_date = df.datadate.unique()\n",
    "    # start after a year\n",
    "    start = 252\n",
    "    turbulence_index = [0]*start\n",
    "    #turbulence_index = [0]\n",
    "    count=0\n",
    "    for i in range(start,len(unique_date)):\n",
    "        current_price = df_price_pivot[df_price_pivot.index == unique_date[i]]\n",
    "        hist_price = df_price_pivot[[n in unique_date[0:i] for n in df_price_pivot.index ]]\n",
    "        cov_temp = hist_price.cov()\n",
    "        current_temp=(current_price - np.mean(hist_price,axis=0))\n",
    "        temp = current_temp.values.dot(np.linalg.inv(cov_temp)).dot(current_temp.values.T)\n",
    "        if temp>0:\n",
    "            count+=1\n",
    "            if count>2:\n",
    "                turbulence_temp = temp[0][0]\n",
    "            else:\n",
    "                #avoid large outlier because of the calculation just begins\n",
    "                turbulence_temp=0\n",
    "        else:\n",
    "            turbulence_temp=0\n",
    "        turbulence_index.append(turbulence_temp)\n",
    "    \n",
    "    \n",
    "    turbulence_index = pd.DataFrame({'datadate':df_price_pivot.index,\n",
    "                                     'turbulence':turbulence_index})\n",
    "    return turbulence_index\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb6c70b-52d5-496a-b377-b75b6c7c1c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775626ca-bc2d-47b8-a7c5-d5a5d553327f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b9b73f-e40f-4894-bd61-9fbaa232a06f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f155ee04-f0c2-46a0-801d-0267e4dd449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates.columns = [\"date\"]\n",
    "dates.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6459237e-7e55-4b0b-b5f6-eafd000033ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afbd9be-9f06-4b87-8b28-21e643e57eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates.sort_values(kind=\"quicksort\", by=\"date\", ascending=True,key=abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a348f69-5e1f-4b21-9752-fae0687dd26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(dates['date']).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7a4bb5-1307-4585-a755-76a04a8936b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_ = []\n",
    "\n",
    "for i in range(0,len((dates['date']).values)):\n",
    "    #print(i)\n",
    "    #dates['date'].values[i] = str(dates['date'].values[i].copy())\n",
    "    dates_.append(str(dates['date'].values[i].copy()))\n",
    "#list((dates['date']).values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265991eb-a6fc-47b0-a4ac-d1e6232a39a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_time = []\n",
    "for i in range(0,len(dates)):\n",
    "    date_time.append(dt.datetime.strptime(dates_[i], '%Y%m%d').strftime('%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1318a6a-b676-445b-8e7b-0102c360aa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57820a08-ca24-4f31-86ac-4a52993dac9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e882f08-511a-4ee6-b166-c5b25de4a5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b33e539-c430-487a-ab3e-44a2c2a74107",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n0 = 9\n",
    "n1 = 12\n",
    "n2 = 26\n",
    "n3 = 14\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c84734-2fa2-48d0-9149-f2dec8bc7c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53d49c7-e253-4238-8be8-1c317d1383de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d120999c-6323-4226-aa31-8e5652e34940",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = data.tic.unique()\n",
    "symbols=stocks\n",
    "start = start_#date_time[0]\n",
    "early_start = (datetime.datetime.strptime(start, '%Y-%m-%d') - pd.tseries.offsets.BusinessDay(n = np.max([n0,n1,n2,n3])+5)).strftime('%Y-%m-%d')\n",
    "end = (datetime.datetime.strptime(str(end_), '%Y-%m-%d') + pd.tseries.offsets.BusinessDay(n = 1)).strftime('%Y-%m-%d')#date_time[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740b4b9d-7767-4df1-b4af-e9ce59cf7ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132df7ad-de72-4503-9bb5-43f6a0c1d5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a calendar\n",
    "nyse = mcal.get_calendar('NYSE')\n",
    "early = nyse.schedule(start_date=early_start, end_date=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1969b6-6bd8-433a-a578-ebbfa049ff63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762f80dd-c0de-4f72-b123-b745b6aea41f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8a8c5f-3b1e-47bc-b746-98aaba2bc94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#truncated_start = early.index.strftime('%Y-%m-%d').get_loc(start)-(np.max([n0,n1,n2,n3]))\n",
    "#start = early.index[truncated_start].strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7471064-863a-4c37-a744-e13af1c65874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a07eaf8-732c-4f13-a159-1de0597d2fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_forward = 40\n",
    "start_date = start\n",
    "end_date = end\n",
    "\n",
    "dataSet = pd.DataFrame()\n",
    "\n",
    "#testSize = 3\n",
    "testSize = len(symbols)\n",
    "\n",
    "#for i in symbols:\n",
    "for i in pd.DataFrame(symbols).sample(testSize).values.ravel():\n",
    "    print(i)\n",
    "    \n",
    "    name = i\n",
    "    ticker = yfinance.Ticker(i)\n",
    "    data_ = ticker.history(interval=\"1d\",start=early_start,end=end_date)\n",
    "    data_['tic'] = i\n",
    "    \n",
    "    exp1 = data_.Close.ewm(span=n1, adjust=False).mean()\n",
    "    exp2 = data_.Close.ewm(span=n2, adjust=False).mean()\n",
    "    macd = (exp1-exp2)/exp2\n",
    "    exp3 = macd.ewm(span=n0, adjust=False).mean()\n",
    "    macd_ = pd.concat([macd,exp3],axis=1)\n",
    "    macd_.columns =[\"macd\",\"signal\"]\n",
    "    data_[['ADX']] = ADX(data_,n3)[['ADX']]\n",
    "    rsi_ = rsi(data_[['Close']])\n",
    "    rsi_.columns = ['rsi']\n",
    "    rsi_    #print(temp)\n",
    "    cci_ = CCI(data_.copy(),n3)[['TP','sma','mad','CCI']]\n",
    "    temp1 = data_[['tic','Close']]\n",
    "    temp1[['datadate']] = temp1.index\n",
    "    temp1.columns = ['tic','adjcp','datadate']\n",
    "    \n",
    "    df = data_.reset_index()\n",
    "    df.columns = ['datadate', 'Open', 'High', 'Low', 'adjcp', 'Volume', 'Dividends','Stock Splits', 'tic', 'ADX']\n",
    "    #df.index = df['datadate']\n",
    "    \n",
    "    #plt.plot(temp, macd, label='AMD MACD', color = '#EBD2BE')\n",
    "    #plt.plot(df.ds, exp3, label='Signal Line', color='#E5A4CB')\n",
    "    #plt.legend(loc='upper left')\n",
    "    #plt.show()    \n",
    "    \n",
    "    turb_ = add_turbulence(df)[['turbulence']]\n",
    "    turb_.index = df['datadate']\n",
    "    #print(turb_.tail())\n",
    "    \n",
    "    data_new = pd.concat([data_,cci_,macd_,rsi_,turb_],axis=1).reset_index()\n",
    "    data_new.columns = ['datadate','Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits', 'tic', 'ADX', 'TP', 'sma', 'mad', 'CCI', 'macd', 'signal', 'rsi', 'turbulence']\n",
    "    \n",
    "    dataSet = pd.concat([dataSet,data_new],axis=0,ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24da26d8-9eda-43fc-8d42-82278b0912be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataSet[['datadate']].set_index('datadate').index.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deb97ed-6566-42f0-b01b-fea192fb4160",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet.datadate = dataSet.set_index('datadate').index.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75cefa8-43c4-4436-9ee9-42776b293625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ed2239-5266-4928-b4fe-47aca7534f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[datadate,tic,adjcp,open,high,low,volume,macd,rsi,cci,adx,turbulence]\n",
    "\n",
    "truncatedDataSet = pd.DataFrame()\n",
    "\n",
    "for i in dataSet.tic.unique():\n",
    "    print(i)\n",
    "    df = dataSet[dataSet.tic==i]\n",
    "    df2 = df[df.set_index('datadate').index.get_loc(datetime.datetime.strptime(start_, \"%Y-%m-%d\").date().strftime('%Y%m%d')):df.set_index('datadate').index.get_loc(datetime.datetime.strptime(end_, \"%Y-%m-%d\").date().strftime('%Y%m%d'))]\n",
    "    #print(df2.head(30))\n",
    "    #print(df2.tail())\n",
    "    truncatedDataSet = pd.concat([truncatedDataSet.copy(),df2],axis=0)\n",
    "    \n",
    "#'low', 'adjcp', 'open', 'volume', 'cci', 'adx', 'high'\n",
    "truncatedDataSet.columns = ['datadate', 'open', 'high', 'low', 'adjcp', 'volume', 'Dividends', \\\n",
    "       'Stock Splits', 'tic', 'adx', 'TP', 'sma', 'mad', 'cci', 'macd', \\\n",
    "       'signal', 'rsi', 'turbulence']\n",
    "\n",
    "truncatedDataSet[truncatedDataSet.columns].to_csv('done_data2.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07be4016-11de-4b09-8e21-b94fa4418ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# read and preprocess data\n",
    "preprocessed_path = \"done_data2.csv\"\n",
    "if os.path.exists(preprocessed_path):\n",
    "    data = pd.read_csv(preprocessed_path, index_col=0)\n",
    "else:\n",
    "    data = preprocess_data()\n",
    "    data = add_turbulence(data)\n",
    "    data.to_csv(preprocessed_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c94332-920a-4bda-b694-791966703017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c442909-5f2b-4ff7-ab8d-3ac038055fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6669cff-c0d2-4387-90b5-326821924861",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_trade_date = data[(data.datadate > 20151001)&(data.datadate <= 20200707)].datadate.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ea0532-d25d-4952-90f2-09248b6416f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebd7a6b-68e0-4061-836a-b3be591fc083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8985204-5f3f-4463-ad7f-82a92487d257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0103309a-832f-4912-9d6e-f1400832b962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825a567e-4f61-49df-9ec2-bd2e8fd24215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8a8e3a-4d78-4033-9255-7f259ff7cf93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
