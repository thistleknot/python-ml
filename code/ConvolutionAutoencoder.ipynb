{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "huutQVSwrbv9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, UpSampling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rgW8cOairbv_"
   },
   "outputs": [],
   "source": [
    "np.random.seed(11)\n",
    "tf.random.set_seed(11)\n",
    "batch_size = 128\n",
    "max_epochs = 50\n",
    "filters = [32,32,16]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vPb5NiOcrbwB",
    "outputId": "13cbe120-1445-41a0-a8ee-c5d8cb9b069e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, _), (x_test, _) = K.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "\n",
    "x_train = np.reshape(x_train, (len(x_train),28, 28, 1))\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
    "\n",
    "noise = 0.5\n",
    "x_train_noisy = x_train + noise * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
    "x_test_noisy = x_test + noise * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0, 1)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0, 1)\n",
    "\n",
    "x_train_noisy = x_train_noisy.astype('float32')\n",
    "x_test_noisy = x_test_noisy.astype('float32')\n",
    "\n",
    "#print(x_test_noisy[1].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "10gjVXStrbwC"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(K.layers.Layer):\n",
    "    def __init__(self, filters):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = Conv2D(filters=filters[0], kernel_size=3, strides=1, activation='relu', padding='same')\n",
    "        self.conv2 = Conv2D(filters=filters[1], kernel_size=3, strides=1, activation='relu', padding='same')\n",
    "        self.conv3 = Conv2D(filters=filters[2], kernel_size=3, strides=1, activation='relu', padding='same')\n",
    "        self.pool = MaxPooling2D((2, 2), padding='same')\n",
    "               \n",
    "    \n",
    "    def call(self, input_features):\n",
    "        x = self.conv1(input_features)\n",
    "        #print(\"Ex1\", x.shape)\n",
    "        x = self.pool(x)\n",
    "        #print(\"Ex2\", x.shape)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "OEjWhvjqrbwD"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Decoder(K.layers.Layer):\n",
    "    def __init__(self, filters):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.conv1 = Conv2D(filters=filters[2], kernel_size=3, strides=1, activation='relu', padding='same')\n",
    "        self.conv2 = Conv2D(filters=filters[1], kernel_size=3, strides=1, activation='relu', padding='same')\n",
    "        self.conv3 = Conv2D(filters=filters[0], kernel_size=3, strides=1, activation='relu', padding='valid')\n",
    "        self.conv4 = Conv2D(1, 3, 1, activation='sigmoid', padding='same')\n",
    "        self.upsample = UpSampling2D((2, 2))\n",
    "  \n",
    "    def call(self, encoded):\n",
    "        x = self.conv1(encoded)\n",
    "        #print(\"dx1\", x.shape)\n",
    "        x = self.upsample(x)\n",
    "        #print(\"dx2\", x.shape)\n",
    "        x = self.conv2(x)\n",
    "        x = self.upsample(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.upsample(x)\n",
    "        return self.conv4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vW2F7zkrrbwF"
   },
   "outputs": [],
   "source": [
    "class Autoencoder(K.Model):\n",
    "    def __init__(self, filters):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.loss = []\n",
    "        self.encoder = Encoder(filters)\n",
    "        self.decoder = Decoder(filters)\n",
    "\n",
    "    def call(self, input_features):\n",
    "        #print(input_features.shape)\n",
    "        encoded = self.encoder(input_features)\n",
    "        #print(encoded.shape)\n",
    "        reconstructed = self.decoder(encoded)\n",
    "        #print(reconstructed.shape)\n",
    "        return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "__T5RzFkrbwF",
    "outputId": "2118ed31-5565-4ecc-f97e-bb7b541c4ce6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "469/469 [==============================] - 21s 31ms/step - loss: 0.2049 - val_loss: 0.1507\n",
      "Epoch 2/50\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.1415 - val_loss: 0.1321\n",
      "Epoch 3/50\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.1287 - val_loss: 0.1238\n",
      "Epoch 4/50\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.1223 - val_loss: 0.1191\n",
      "Epoch 5/50\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.1181 - val_loss: 0.1152\n",
      "Epoch 6/50\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.1150 - val_loss: 0.1126\n",
      "Epoch 7/50\n",
      "469/469 [==============================] - 13s 29ms/step - loss: 0.1126 - val_loss: 0.1105\n",
      "Epoch 8/50\n",
      "469/469 [==============================] - 15s 31ms/step - loss: 0.1109 - val_loss: 0.1092\n",
      "Epoch 9/50\n",
      "469/469 [==============================] - 14s 31ms/step - loss: 0.1094 - val_loss: 0.1081\n",
      "Epoch 10/50\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.1082 - val_loss: 0.1072\n",
      "Epoch 11/50\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.1072 - val_loss: 0.1065\n",
      "Epoch 12/50\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.1064 - val_loss: 0.1057\n",
      "Epoch 13/50\n",
      "469/469 [==============================] - 13s 29ms/step - loss: 0.1057 - val_loss: 0.1048\n",
      "Epoch 14/50\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.1052 - val_loss: 0.1039\n",
      "Epoch 15/50\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.1045 - val_loss: 0.1033\n",
      "Epoch 16/50\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.1041 - val_loss: 0.1032\n",
      "Epoch 17/50\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.1037 - val_loss: 0.1031\n",
      "Epoch 18/50\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.1032 - val_loss: 0.1024\n",
      "Epoch 19/50\n",
      "469/469 [==============================] - 14s 31ms/step - loss: 0.1029 - val_loss: 0.1019\n",
      "Epoch 20/50\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.1025 - val_loss: 0.1015\n",
      "Epoch 21/50\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.1023 - val_loss: 0.1014\n",
      "Epoch 22/50\n",
      "469/469 [==============================] - 14s 31ms/step - loss: 0.1020 - val_loss: 0.1020\n",
      "Epoch 23/50\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.1019 - val_loss: 0.1012\n",
      "Epoch 24/50\n",
      "469/469 [==============================] - 15s 31ms/step - loss: 0.1016 - val_loss: 0.1012\n",
      "Epoch 25/50\n",
      "469/469 [==============================] - 15s 31ms/step - loss: 0.1014 - val_loss: 0.1010\n",
      "Epoch 26/50\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.1012 - val_loss: 0.1013\n",
      "Epoch 27/50\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.1009 - val_loss: 0.1003\n",
      "Epoch 28/50\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.1008 - val_loss: 0.1004\n",
      "Epoch 29/50\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.1007 - val_loss: 0.1004\n",
      "Epoch 30/50\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.1005 - val_loss: 0.1000\n",
      "Epoch 31/50\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.1005 - val_loss: 0.1009\n",
      "Epoch 32/50\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.1003 - val_loss: 0.1006\n",
      "Epoch 33/50\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.1001 - val_loss: 0.0996\n",
      "Epoch 34/50\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.1000 - val_loss: 0.0999\n",
      "Epoch 35/50\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 0.1000 - val_loss: 0.1001\n",
      "Epoch 36/50\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0998 - val_loss: 0.0993\n",
      "Epoch 37/50\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0997 - val_loss: 0.0993\n",
      "Epoch 38/50\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0997 - val_loss: 0.0992\n",
      "Epoch 39/50\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 0.0995 - val_loss: 0.0990\n",
      "Epoch 40/50\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 0.0995 - val_loss: 0.0992\n",
      "Epoch 41/50\n",
      "469/469 [==============================] - 16s 35ms/step - loss: 0.0994 - val_loss: 0.0988\n",
      "Epoch 42/50\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 0.0993 - val_loss: 0.0991\n",
      "Epoch 43/50\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.0993 - val_loss: 0.0988\n",
      "Epoch 44/50\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 0.0991 - val_loss: 0.0986\n",
      "Epoch 45/50\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.0991 - val_loss: 0.0991\n",
      "Epoch 46/50\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.0991 - val_loss: 0.0987\n",
      "Epoch 47/50\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 0.0990 - val_loss: 0.0988\n",
      "Epoch 48/50\n",
      "469/469 [==============================] - 16s 35ms/step - loss: 0.0989 - val_loss: 0.0982\n",
      "Epoch 49/50\n",
      "469/469 [==============================] - 17s 35ms/step - loss: 0.0988 - val_loss: 0.0988\n",
      "Epoch 50/50\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 0.0988 - val_loss: 0.0987\n"
     ]
    }
   ],
   "source": [
    "model = Autoencoder(filters)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "loss = model.fit(x_train_noisy,\n",
    "                x_train,\n",
    "                validation_data=(x_test_noisy, x_test),\n",
    "                epochs=max_epochs,\n",
    "                batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "rvid4TwYrbwH",
    "outputId": "fa029a01-7daf-4028-d965-70e2c1ed78fc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(range(max_epochs), loss.history['loss'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "JU8yjR4JrbwI",
    "outputId": "f30cf71a-1a20-447f-ac8d-489f8e472b5f"
   },
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[10000,32,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# display reconstruction\u001b[39;00m\n\u001b[0;32m     11\u001b[0m ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m2\u001b[39m, number, index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m number)\n\u001b[1;32m---> 12\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(tf\u001b[38;5;241m.\u001b[39mreshape(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test_noisy\u001b[49m\u001b[43m)\u001b[49m[index], (\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m)), cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m ax\u001b[38;5;241m.\u001b[39mget_xaxis()\u001b[38;5;241m.\u001b[39mset_visible(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m ax\u001b[38;5;241m.\u001b[39mget_yaxis()\u001b[38;5;241m.\u001b[39mset_visible(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1030\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1026\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1029\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1030\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m call_fn(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1033\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36mAutoencoder.call\u001b[1;34m(self, input_features)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_features):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m#print(input_features.shape)\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m#print(encoded.shape)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     reconstructed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(encoded)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1030\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1026\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1029\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1030\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m call_fn(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1033\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mEncoder.call\u001b[1;34m(self, input_features)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_features):\n\u001b[1;32m---> 11\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m#print(\"Ex1\", x.shape)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1030\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1026\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1029\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1030\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m call_fn(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1033\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py:249\u001b[0m, in \u001b[0;36mConv.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_causal:  \u001b[38;5;66;03m# Apply causal padding to inputs for Conv1D.\u001b[39;00m\n\u001b[0;32m    247\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mpad(inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_causal_padding(inputs))\n\u001b[1;32m--> 249\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convolution_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_bias:\n\u001b[0;32m    252\u001b[0m   output_rank \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    209\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1012\u001b[0m, in \u001b[0;36mconvolution_v2\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1002\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnn.convolution\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvolution_v2\u001b[39m(  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1010\u001b[0m     dilations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1011\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1012\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvolution_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=redefined-builtin\u001b[39;49;00m\n\u001b[0;32m   1014\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdilations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdilations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1142\u001b[0m, in \u001b[0;36mconvolution_internal\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[0;32m   1139\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1140\u001b[0m     op \u001b[38;5;241m=\u001b[39m conv1d\n\u001b[1;32m-> 1142\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdilations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdilations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1151\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m channel_index \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:2596\u001b[0m, in \u001b[0;36m_conv2d_expanded_batch\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   2592\u001b[0m input_rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\n\u001b[0;32m   2593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_rank \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m input_rank \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m5\u001b[39m:\n\u001b[0;32m   2594\u001b[0m   \u001b[38;5;66;03m# We avoid calling squeeze_batch_dims to reduce extra python function\u001b[39;00m\n\u001b[0;32m   2595\u001b[0m   \u001b[38;5;66;03m# call slowdown in eager mode.  This branch doesn't require reshapes.\u001b[39;00m\n\u001b[1;32m-> 2596\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_nn_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2597\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2598\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2599\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2600\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2601\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2602\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdilations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdilations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2603\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2604\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m squeeze_batch_dims(\n\u001b[0;32m   2605\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   2606\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2613\u001b[0m     inner_rank\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m   2614\u001b[0m     name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:935\u001b[0m, in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m    933\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 935\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconv2d_eager_fallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    936\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cudnn_on_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cudnn_on_gpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    937\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplicit_paddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplicit_paddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdilations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_SymbolicException:\n\u001b[0;32m    940\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:1024\u001b[0m, in \u001b[0;36mconv2d_eager_fallback\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name, ctx)\u001b[0m\n\u001b[0;32m   1020\u001b[0m _inputs_flat \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mfilter\u001b[39m]\n\u001b[0;32m   1021\u001b[0m _attrs \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m, _attr_T, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrides\u001b[39m\u001b[38;5;124m\"\u001b[39m, strides, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cudnn_on_gpu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1022\u001b[0m use_cudnn_on_gpu, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpadding\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexplicit_paddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1023\u001b[0m explicit_paddings, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_format\u001b[39m\u001b[38;5;124m\"\u001b[39m, data_format, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdilations\u001b[39m\u001b[38;5;124m\"\u001b[39m, dilations)\n\u001b[1;32m-> 1024\u001b[0m _result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mConv2D\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_inputs_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n\u001b[0;32m   1027\u001b[0m   _execute\u001b[38;5;241m.\u001b[39mrecord_gradient(\n\u001b[0;32m   1028\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConv2D\u001b[39m\u001b[38;5;124m\"\u001b[39m, _inputs_flat, _attrs, _result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10000,32,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "number = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for index in range(number):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, number, index + 1)\n",
    "    plt.imshow(x_test_noisy[index].reshape(28, 28), cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, number, index + 1 + number)\n",
    "    plt.imshow(tf.reshape(model(x_test_noisy)[index], (28, 28)), cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ConvolutionAutoencoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
