{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d27cc9-ceca-47c9-8ee4-96c9a7fbf2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"suolyer/pile_philpapers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e046500b-0a68-4a13-9c2f-c9e2956f546e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eec5dc-fb6b-4b2b-801c-7732709924bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c514692-b06d-4c33-8ec7-a61c89f83892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e1270b-6745-4e5d-9815-021049e9d29a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fc470c-1497-4f0f-bfa2-f95cdc5e0830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdafc4a3-850c-4ec7-ad5c-d7e4dc695e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521a346e-aa9d-402d-85b7-8e6d28939227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075e8579-24b9-481d-88b0-ab61386ec96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "quotes = []\n",
    "\n",
    "parent_url = \"https://graciousquotes.com/all/\"\n",
    "response = requests.get(parent_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # Find all h3 elements with class 'wp-block-heading'\n",
    "    h3_elements = soup.find_all('h3', class_='wp-block-heading')\n",
    "    \n",
    "    for h3 in h3_elements:\n",
    "        section_title = h3.get_text(strip=True)\n",
    "        print(f\"Processing section: {section_title}\")\n",
    "        \n",
    "        # Find all the links under the current section\n",
    "        p_element = h3.find_next_sibling('p')\n",
    "        links = p_element.find_all('a')\n",
    "        \n",
    "        for link in links:\n",
    "            child_url = link['href']\n",
    "            print(f\"Processing link: {child_url}\")\n",
    "            \n",
    "            child_response = requests.get(child_url)\n",
    "            if child_response.status_code == 200:\n",
    "                child_html = child_response.text\n",
    "                child_soup = BeautifulSoup(child_html, 'html.parser')\n",
    "                \n",
    "                # Extract quotes from child page\n",
    "                figcaptions = child_soup.find_all('figcaption')\n",
    "                for figcaption in figcaptions:\n",
    "                    quotes.append(figcaption.text.strip())\n",
    "                    print(figcaption.text.strip())\n",
    "            else:\n",
    "                print(f\"Failed to retrieve the child page: {child_url}\")\n",
    "else:\n",
    "    print(\"Failed to retrieve the parent page.\")\n",
    "    \n",
    "pd.DataFrame(quotes).to_csv('graciousquotes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043fbbca-0d1c-4aa3-baf2-48cade7f8f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5720e1d0-e63e-4d94-9055-3c7f9bbb51c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Data\n",
    "BASE_URL = \"https://www.azquotes.com\"\n",
    "AUTHORS_URL = f\"{BASE_URL}/quotes/authors.html\"\n",
    "AUTHOR_SINGLE_URL = f\"{BASE_URL}/quotes/authors\"\n",
    "QUOTES_BY_AUTHOR_URL = f\"{BASE_URL}/author\"\n",
    "\n",
    "# Selectors\n",
    "AUTHORS_TABLES_SELECTOR = \".authors-page ul\"\n",
    "AUTHORS_LIST_SELECTOR = \".leftcol-inner .table tbody tr\"\n",
    "AUTHORS_PAGINATION_SELECTOR = \".table + .pager li\"\n",
    "AUTHOR_SINGLE_PAGINATION_SELECTOR = \".pager li\"\n",
    "QUOTES_LIST_SELECTOR = \"ul.list-quotes li\"\n",
    "\n",
    "# Get all authors\n",
    "def get_authors():\n",
    "    response = requests.get(AUTHORS_URL)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        authors_tables = soup.select(AUTHORS_TABLES_SELECTOR)\n",
    "        authors = []\n",
    "        for table in authors_tables:\n",
    "            links = table.find_all('a')\n",
    "            for link in links:\n",
    "                authors.append({'name': link.text.strip(), 'link': link['href'].replace('/author/', '')})\n",
    "        return authors\n",
    "    return []\n",
    "\n",
    "# Get the number of pages for an author\n",
    "def get_author_pagination(author_link):\n",
    "    response = requests.get(f\"{AUTHOR_SINGLE_URL}/{author_link}\")\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        pagination = soup.select(AUTHOR_SINGLE_PAGINATION_SELECTOR)\n",
    "        pages = []\n",
    "        for page in pagination:\n",
    "            page_text = page.find('a').text\n",
    "            if page_text.isdigit():\n",
    "                pages.append(int(page_text))\n",
    "        return max(pages) if pages else 1\n",
    "    return 1\n",
    "\n",
    "# Get quotes by author\n",
    "# Get quotes by author\n",
    "def get_quotes_by_author(author_link, page=1):\n",
    "    response = requests.get(f\"{QUOTES_BY_AUTHOR_URL}/{author_link}/{page}\")\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        quote_lis = soup.select(QUOTES_LIST_SELECTOR)\n",
    "        quotes = []\n",
    "        for quote_li in quote_lis:\n",
    "            if not quote_li.find(\"div\", class_=\"wrap-block-for-ad\"):\n",
    "                quote_a = quote_li.find('a')\n",
    "                if quote_a:\n",
    "                    quotes.append(quote_a.text.strip())\n",
    "                else:\n",
    "                    print(f\"Warning: No 'a' tag found in quote_li: {quote_li}\")\n",
    "        return quotes\n",
    "    return []\n",
    "\n",
    "# Main script\n",
    "authors = get_authors()\n",
    "quotes = []\n",
    "\n",
    "for author in authors:\n",
    "    author_link = author['link']\n",
    "    num_pages = get_author_pagination(author_link)\n",
    "\n",
    "    for page in range(1, num_pages + 1):\n",
    "        author_quotes = get_quotes_by_author(author_link, page)\n",
    "        quotes.extend(author_quotes)\n",
    "\n",
    "# Save quotes to a CSV file\n",
    "pd.DataFrame(quotes).to_csv('quotes_by_author.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af62b06d-ee09-426e-a84e-46b96bbff229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
