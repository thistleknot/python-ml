{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60d6f37f-5db5-4eb3-aac6-344be2e38cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "#import streamlit as st\n",
    "from tqdm import tqdm\n",
    "from haystack import Pipeline\n",
    "from haystack.document_stores import FAISSDocumentStore, SQLDocumentStore\n",
    "from haystack.document_stores.memory import InMemoryDocumentStore\n",
    "from haystack.nodes.retriever.dense import DensePassageRetriever, DPRQuestionEncoderTokenizerFast, DPRContextEncoderTokenizerFast\n",
    "from haystack.nodes.reader import FARMReader\n",
    "from haystack.pipelines import ExtractiveQAPipeline, GenerativeQAPipeline\n",
    "from haystack.utils import print_answers\n",
    "from haystack.nodes import RAGenerator\n",
    "from haystack.nodes import Shaper, PromptNode, PromptTemplate, PromptModel, EmbeddingRetriever\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b8f211-2cb7-4afa-9f89-ad2c48d19d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51db476-41d8-4d0c-8938-b066e0f913ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de2c229-f3a4-4dba-ac06-09650e4589c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a96aa5-d0a0-41c2-a74c-ef64009aecd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871b3dae-f16f-48d9-ab0e-007b2396f265",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.exists('document_store.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de769e3-7b78-4071-b397-6965df668ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#document_store = SQLDocumentStore(db_path)\n",
    "\n",
    "if(os.path.exists('document_store.pkl')):\n",
    "    document_store =  pickle.load(open('./document_store.pkl', 'rb'))\n",
    "    retriever = DensePassageRetriever(\n",
    "        document_store=document_store,\n",
    "        query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n",
    "        passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n",
    "        use_gpu=False,\n",
    "        #embed_title=True,\n",
    "    )\n",
    "    \n",
    "    # Initialize RAG Generator\n",
    "    generator = RAGenerator(\n",
    "        model_name_or_path=\"facebook/rag-token-nq\",\n",
    "        use_gpu=True,\n",
    "        max_length=50,\n",
    "        min_length=20,\n",
    "        #embed_title=True,\n",
    "        num_beams=5,\n",
    "        #tokenizer=BartTokenizerFast.from_pretrained('facebook/rag-token-nq'),\n",
    "        retriever=retriever\n",
    "    )\n",
    "else:\n",
    "\n",
    "    dataset = load_dataset(\"EleutherAI/wikitext_document_level\",'wikitext-103-v1')\n",
    "\n",
    "    merged_data = {}\n",
    "    for partition in ['train', 'test', 'validation']:\n",
    "        if partition in dataset:\n",
    "            for i in range(len(dataset[partition])):\n",
    "                page = dataset[partition][i]['page']\n",
    "                title = page.split('=', 2)[1].strip()\n",
    "                text = page.split('=', 2)[2].strip()\n",
    "                merged_data[title] = text\n",
    "\n",
    "    article_names = list(merged_data.keys())\n",
    "\n",
    "    print(article_names[0])\n",
    "    print(merged_data[article_names[0]])\n",
    "\n",
    "    #from haystack.document_store.faiss import FAISSDocumentStore\n",
    "\n",
    "    # set the path to the SQLite database file\n",
    "    db_path = \"sqlite:///document_store.db\"\n",
    "\n",
    "\n",
    "    document_store = InMemoryDocumentStore()\n",
    "\n",
    "    # Create a dictionary to store the documents\n",
    "    documents = []\n",
    "\n",
    "    # Write the documents to the document store\n",
    "    #document_store.write_documents(documents)\n",
    "\n",
    "    #print(document_store.get_all_documents())\n",
    "\n",
    "    document_store.delete_documents()\n",
    "    # Delete existing documents in documents store\n",
    "\n",
    "    # Initialize document store\n",
    "    # Add search snippets to document store\n",
    "\n",
    "    #for k in tqdm(list(merged_data.keys())[0:100]):\n",
    "    for k in tqdm(list(merged_data.keys())):\n",
    "        document_store.write_documents([{\n",
    "            \"content\": merged_data[k],\n",
    "            \"meta\": {\n",
    "                \"title\": k,\n",
    "            }\n",
    "        }])\n",
    "\n",
    "    retriever = DensePassageRetriever(\n",
    "    document_store=document_store,\n",
    "    query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n",
    "    passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n",
    "    use_gpu=True,\n",
    "    #embed_title=True,\n",
    ")\n",
    "    document_store.update_embeddings(retriever=retriever)\n",
    "\n",
    "    # Initialize RAG Generator\n",
    "    generator = RAGenerator(\n",
    "        model_name_or_path=\"facebook/rag-token-nq\",\n",
    "        use_gpu=True,\n",
    "        max_length=50,\n",
    "        min_length=20,\n",
    "        #embed_title=True,\n",
    "        num_beams=5,\n",
    "        #tokenizer=BartTokenizerFast.from_pretrained('facebook/rag-token-nq'),\n",
    "        retriever=retriever\n",
    "    )\n",
    "    pickle.dump(document_store, open('document_store.pkl', 'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c50e5c-e954-4a51-bad9-9488bd41c897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9df3a4f-8152-4fdb-a2ba-a19104720fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e5111b-9187-49a5-a86e-2ce923b5d4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acab194-930e-4340-9cd8-03a04170bede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835acce9-c711-44d0-880e-8a220fcbcb34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1ffbb8-753d-4181-acf7-c0dd4d83b809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87224c3d-b1fa-44a9-9b00-f80607cb944f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f788690-3780-43d7-b17c-34dc5fe600ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306a7f57-a5ce-4680-8162-9d73277fbca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bad18b8-0991-4ecc-821f-205e3a1dc9cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751b5446-7434-4042-b0f7-ef56d15a64fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6a63b2-4682-4369-9002-fdf085fc39bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46960f6f-9697-4e8b-ade7-dcb8bd41f45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "\n",
    "def get_gpt2_embeddings(texts, model, tokenizer):\n",
    "    tokenized_texts = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    input_ids = tokenized_texts[\"input_ids\"]\n",
    "    attention_mask = tokenized_texts[\"attention_mask\"]\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    embeddings = outputs[0][:, 0, :].numpy()\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"vicgalle/gpt2-alpaca-gpt4\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"vicgalle/gpt2-alpaca-gpt4\")\n",
    "#model = GPT2Model.from_pretrained(\"vicgalle/gpt2-alpaca-gpt4\")\n",
    "\n",
    "embeddings = get_gpt2_embeddings(joined_texts, model, tokenizer)\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "def create_faiss_index(embeddings):\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    faiss.normalize_L2(embeddings)\n",
    "    index.add(embeddings)\n",
    "    return index\n",
    "\n",
    "index = create_faiss_index(np.ascontiguousarray(embeddings))\n",
    "\n",
    "#4. Perform a similarity search using the Faiss index:\n",
    "\n",
    "def search_faiss_index(query, model, tokenizer, index, k=5):\n",
    "    query_embedding = get_gpt2_embeddings([query], model, tokenizer)\n",
    "    faiss.normalize_L2(query_embedding)\n",
    "    _, indices = index.search(query_embedding, k)\n",
    "    return indices[0]\n",
    "\n",
    "result_indices = search_faiss_index(query, model, tokenizer, index, k=2)\n",
    "print(result_indices)\n",
    "\n",
    "\n",
    "def generate_response(prompt, model, tokenizer, max_length=256):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=1,\n",
    "            no_repeat_ngram_size=2,\n",
    "            top_k=5,\n",
    "            top_p=0.95,\n",
    "            temperature=0.8,\n",
    "        )\n",
    "\n",
    "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f951c5-b390-42c1-8a54-c97a4682bdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(a.context, a.answer) for a in prediction['answers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6c50e2-3794-4f3b-b73a-f569902cbfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [['C:' + \"\\n\\n\" + a.context + \"\\n\\n\" + 'A:' + \"\\n\\n\" +  a.answer + \"\\n\\n\"] for a in prediction['answers']]\n",
    "\n",
    "for t in texts:\n",
    "    print(t[0])\n",
    "    \n",
    "string_output = 'Q:\\n\\n' + query + '\\n\\n'\n",
    "for a in prediction['answers']:\n",
    "    string_output += 'C: \\n\\n' + a.context + '\\n\\n'\n",
    "    string_output += 'A: \\n\\n' + a.answer + '\\n\\n'\n",
    "print(string_output)\n",
    "\n",
    "context = \" \".join([joined_texts[i] for i in result_indices])\n",
    "prompt = f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "### Instruction:\n",
    "\n",
    "Given the below as context:\n",
    "\n",
    "Start context:\n",
    "\n",
    "{string_output}\n",
    ":End context.\n",
    "\n",
    "Using the above as contextAnswer the below question or perform the asked for task:\n",
    "\n",
    "{query}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "print(prompt)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc670a0-36bc-4fbb-83b1-0f93fba98c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = generate_response(prompt,model,tokenizer,max_length=512)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a95a94-e303-4bc4-b9fd-9f330e86c6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19b377d-5bde-4588-a095-8114fee78773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7cf94a-df74-44df-8d4b-d60a3264102a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dd0c4d-914a-4cfd-8197-eeaeb274ec0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a196432c-02a5-48ae-a753-738de465bf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store = FAISSDocumentStore(faiss_index_path=\"my_faiss_index.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0d2652-5537-4b46-bed1-f643f8040af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "faiss_document_store = FAISSDocumentStore(\n",
    "        faiss_index_factory_str=\"Flat\",\n",
    "        return_embedding=True,\n",
    "        embedding_dim=768,\n",
    "        sql_url='sqlite:///testdb.sql',\n",
    "        index=\"title\",\n",
    "        progress_bar=False,\n",
    "    )\n",
    "\n",
    "# Add the documents from the in_memory_document_store to the faiss_document_store\n",
    "documents = document_store.get_all_documents()\n",
    "\n",
    "\n",
    "\n",
    "faiss_document_store.write_documents(documents)\n",
    "retriever_faiss = DensePassageRetriever(\n",
    "    document_store=faiss_document_store,\n",
    "    query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n",
    "    passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n",
    "    use_gpu=True,\n",
    "    #embed_title=True,\n",
    ")\n",
    "\n",
    "retriever = DensePassageRetriever(\n",
    "document_store=faiss_document_store,\n",
    "query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n",
    "passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n",
    "use_gpu=True,\n",
    "#embed_title=True,\n",
    ")\n",
    "faiss_document_store.update_embeddings(retriever=retriever_faiss)\n",
    "faiss_document_store.save(index_path=\"my_faiss_index.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "356f1daa-824c-4ff8-a8b7-aa4656dfe3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "retriever_faiss = DensePassageRetriever(\n",
    "    document_store=document_store,\n",
    "    query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n",
    "    passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n",
    "    use_gpu=True,\n",
    "    #embed_title=True,\n",
    ")\n",
    "document_store.update_embeddings(retriever=retriever_faiss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1275877a-7499-4596-b7ef-6fd11749969b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14568\\2005215197.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'C:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_14568\\\\2005215197.py'</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\User\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\haystack\\nodes\\retriever\\d</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">ense.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">741</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">save</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 738 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">:return: None</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 739 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 740 │   │   </span>save_dir = Path(save_dir)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 741 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model.save(save_dir, lm1_name=query_encoder_dir, lm2_name=passage_encoder_d  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 742 │   │   </span>save_dir = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>(save_dir)                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 743 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.query_tokenizer.save_pretrained(save_dir + <span style=\"color: #808000; text-decoration-color: #808000\">f\"/{</span>query_encoder_dir<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>)          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 744 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.passage_tokenizer.save_pretrained(save_dir + <span style=\"color: #808000; text-decoration-color: #808000\">f\"/{</span>passage_encoder_dir<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>)      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\User\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\haystack\\modeling\\model\\bi</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">adaptive_model.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">105</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">save</span>                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">102 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">103 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">:param save_dir: Path | str to save the BiAdaptiveModel to.</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">104 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>105 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>os.makedirs(save_dir, exist_ok=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">106 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> name, model <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">zip</span>([lm1_name, lm2_name], [<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.language_model1, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.languag   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">107 │   │   │   </span>model_save_dir = Path.joinpath(Path(save_dir), Path(name))                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">108 │   │   │   </span>os.makedirs(model_save_dir, exist_ok=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\os.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">225</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">makedirs</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 222 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> tail == cdir:           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># xxx/newdir/. exists if xxx/newdir exists</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 223 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 224 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 225 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>mkdir(name, mode)                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 226 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">OSError</span>:                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 227 │   │   # Cannot rely on checking for EEXIST, since the operating system</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 228 │   │   # could give priority to other errors like EACCES or EROFS</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">FileExistsError: </span><span style=\"font-weight: bold\">[</span>WinError <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">183</span><span style=\"font-weight: bold\">]</span> Cannot create a file when that file already exists: <span style=\"color: #008000; text-decoration-color: #008000\">'my_faiss_index.faiss'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14568\\2005215197.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'C:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_14568\\\\2005215197.py'\u001b[0m                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\User\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\haystack\\nodes\\retriever\\d\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mense.py\u001b[0m:\u001b[94m741\u001b[0m in \u001b[92msave\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 738 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m:return: None\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 739 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 740 \u001b[0m\u001b[2m│   │   \u001b[0msave_dir = Path(save_dir)                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 741 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.model.save(save_dir, lm1_name=query_encoder_dir, lm2_name=passage_encoder_d  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 742 \u001b[0m\u001b[2m│   │   \u001b[0msave_dir = \u001b[96mstr\u001b[0m(save_dir)                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 743 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.query_tokenizer.save_pretrained(save_dir + \u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m/\u001b[0m\u001b[33m{\u001b[0mquery_encoder_dir\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 744 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.passage_tokenizer.save_pretrained(save_dir + \u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m/\u001b[0m\u001b[33m{\u001b[0mpassage_encoder_dir\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\User\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\haystack\\modeling\\model\\bi\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33madaptive_model.py\u001b[0m:\u001b[94m105\u001b[0m in \u001b[92msave\u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m102 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m103 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m:param save_dir: Path | str to save the BiAdaptiveModel to.\u001b[0m                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m104 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m105 \u001b[2m│   │   \u001b[0mos.makedirs(save_dir, exist_ok=\u001b[94mTrue\u001b[0m)                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m106 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m name, model \u001b[95min\u001b[0m \u001b[96mzip\u001b[0m([lm1_name, lm2_name], [\u001b[96mself\u001b[0m.language_model1, \u001b[96mself\u001b[0m.languag   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m107 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_save_dir = Path.joinpath(Path(save_dir), Path(name))                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m108 \u001b[0m\u001b[2m│   │   │   \u001b[0mos.makedirs(model_save_dir, exist_ok=\u001b[94mTrue\u001b[0m)                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\os.py\u001b[0m:\u001b[94m225\u001b[0m in \u001b[92mmakedirs\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 222 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m tail == cdir:           \u001b[2m# xxx/newdir/. exists if xxx/newdir exists\u001b[0m             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 223 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 224 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mtry\u001b[0m:                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 225 \u001b[2m│   │   \u001b[0mmkdir(name, mode)                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 226 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mOSError\u001b[0m:                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 227 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 228 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# could give priority to other errors like EACCES or EROFS\u001b[0m                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mFileExistsError: \u001b[0m\u001b[1m[\u001b[0mWinError \u001b[1;36m183\u001b[0m\u001b[1m]\u001b[0m Cannot create a file when that file already exists: \u001b[32m'my_faiss_index.faiss'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "retriever_faiss.save('my_faiss_index.faiss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77acb858-c66c-4d62-af2a-92fc32c7e89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\transformers\\models\\bart\\configuration_bart.py:179: UserWarning: Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n",
      "  warnings.warn(\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n",
      "Some weights of the model checkpoint at facebook/rag-token-nq were not used when initializing RagTokenForGeneration: ['rag.question_encoder.question_encoder.bert_model.pooler.dense.bias', 'rag.question_encoder.question_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RagTokenForGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RagTokenForGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RagTokenForGeneration were not initialized from the model checkpoint at facebook/rag-token-nq and are newly initialized: ['rag.generator.lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#document_store.update_embeddings(retriever=retriever)\n",
    "\n",
    "# Initialize RAG Generator\n",
    "generator = RAGenerator(\n",
    "    model_name_or_path=\"facebook/rag-token-nq\",\n",
    "    use_gpu=True,\n",
    "    max_length=50,\n",
    "    min_length=20,\n",
    "    #embed_title=True,\n",
    "    num_beams=5,\n",
    "    #tokenizer=BartTokenizerFast.from_pretrained('facebook/rag-token-nq'),\n",
    "    retriever=retriever_faiss\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c600bb5-f296-4fca-9b41-70f3a03b4531",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=False)\n",
    "\n",
    "pipe = ExtractiveQAPipeline(reader, retriever)\n",
    "\n",
    "prediction = pipe.run(\n",
    "    query, params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 5}}\n",
    ")\n",
    "\n",
    "print_answers(prediction, details=\"minimum\")\n",
    "\n",
    "query = 'Who is Obama?'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2024fb3-3687-4b85-bea4-36b303fabcb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf603cfb-af03-44f9-b33f-46acc228bc60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b30bc4-d76b-4415-af50-a2059d671abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c45bae9-83bc-47d9-ba34-7db7201f62d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e92f2d-fbf5-4cf9-93fd-df211fc2c05e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada3c51b-1d90-4ed8-a0d0-5d69a85edc6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365a279e-21c2-4ff1-84d2-fa346cb15bef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591bef27-3fe6-4b92-bcbb-d80522aa40e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run pipeline\n",
    "pipe = GenerativeQAPipeline(generator=generator, retriever=retriever)\n",
    "res = pipe.run(query=query, params={\"Generator\": {\"top_k\": 5}, \"Retriever\": {\"top_k\": 5}})\n",
    "print_answers(res, details=\"minimum\")\n",
    "\n",
    "for a in res['answers']:\n",
    "    docs = [document_store.get_document_by_id(d) for d in a.document_ids]\n",
    "    titles = [d.meta['title'] for d in docs] \n",
    "    print(a.score, titles, a.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4942d855-52ff-4b42-a4e2-928d0632e4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9065aa1f-4941-4abf-80d8-4afd513fbdbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fb9cb6-e9a3-4cb8-8123-5372a9267982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955fdba3-1a41-45dc-b6d9-b8e41b38c1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d82b58-96c5-42af-98ea-8430d3d3e561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c419088f-f683-4c33-a96c-183086c5fc8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd2fd6f-40a7-4841-9adc-c21c6f1cab4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734240af-a957-41e3-be4e-d761b8a11cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c30b03-6abc-43d0-93cc-ffc456253165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198d0189-a29b-4dcd-87c0-2d4c75211424",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Yes, it is possible to perform a tiered search using clustering to partition the index's smaller `n_dim` embeddings into more refined searches based on their similarity to the query. One approach to achieve this is to use hierarchical clustering, which is a method of cluster analysis that builds a hierarchy of clusters by recursively partitioning data points into smaller clusters based on their similarity. \n",
    "\n",
    "Here's a high-level overview of how you could implement a tiered search using hierarchical clustering:\n",
    "...\n",
    "\n",
    "5. When a query is made, use the `DensePassageRetriever` to retrieve the top `k` clusters that are most similar to the query, based on their embeddings.\n",
    "\n",
    "6. For each of the top `k` clusters, query the corresponding index using the `DensePassageRetriever` to retrieve the top `m` documents that are most similar to the query, based on their embeddings.\n",
    "\n",
    "7. Combine the results from all the indices, and return the top `n` documents as the final results.\n",
    "\n",
    "This approach can help speed up the search process by reducing the number of documents that need to be searched for each query, while also potentially improving the accuracy of the results by using more refined indices for documents that are more similar to the query. However, it also adds additional complexity to the system and requires careful tuning of the clustering and indexing parameters to achieve the desired balance between speed and accuracy.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ff336a-f604-42fc-b452-763d0275337b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70ddd5c-5e2c-41d7-be56-90c41fa36097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d17d78e-cb61-4fea-9c13-1d1d7faf48d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9406bf94-af6b-4ae1-aa21-1d3db6fe014c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07436ea6-1cbb-4cf6-98d9-6cc0fc493ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb5c1f6-3be7-42d7-a752-b7ae0d17be49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe29bc0-ec5a-4bd1-be18-80f92c1102cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21398af9-e43d-4f28-bb7f-60fb06d460d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9ecfee-5d54-42cf-a09a-d9155b7f93e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e90ee53-3256-4e00-8013-98a6c429c019",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
