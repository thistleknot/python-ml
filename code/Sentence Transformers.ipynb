{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9787a179-9d76-4ce5-a30c-df09bc9b0c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import textblob\n",
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "from datasets import load_dataset\n",
    "nltk.download('wordnet')\n",
    "nltk.download('wordnet_ic')\n",
    "import numpy as np\n",
    "import string\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from top2vec import Top2Vec\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "#model = Top2Vec(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c72ecc8-9b85-4efb-a159-ad216bffc542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_common_words(skDocsTfIdfdf, threshold):\n",
    "    # Calculate the sums of the tf-idf values across all the documents\n",
    "    tf_idf_sums = skDocsTfIdfdf.sum(axis=0)\n",
    "    \n",
    "    # Sort the tf-idf values in descending order\n",
    "    sorted_tf_idf_sums = tf_idf_sums.sort_values(ascending=False)\n",
    "    \n",
    "    # Filter out the words with the highest tf-idf values, so that only the top 50% of values are displayed\n",
    "    filtered_tf_idf_sums = sorted_tf_idf_sums[sorted_tf_idf_sums > sorted_tf_idf_sums.quantile(1-threshold)]\n",
    "    return(filtered_tf_idf_sums)\n",
    "    # Return the sorted dataframe\n",
    "\n",
    "    \n",
    "def createVocab_lemma(docs):\n",
    "    vocab={}\n",
    "    for doc in docs:\n",
    "        doc= doc.translate(str.maketrans('', '', string.punctuation))\n",
    "        for word in word_tokenize(doc.lower()):\n",
    "            if word not in vocab.keys():\n",
    "                vocab[word] = 1\n",
    "                # Create a synonym list for each word\n",
    "                word_synsets = [wordnet.synsets(word) for word in word_tokenize(doc.lower())]\n",
    "                synonyms = []\n",
    "                for word_synset in word_synsets:\n",
    "                    if (word_synset):\n",
    "                        for lemma in word_synset[0].lemmas():\n",
    "                            synonyms.append(lemma.name())\n",
    "                vocab[word] = synonyms\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c914314-a3b6-47af-bea9-1c8f40a5452d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cd4245-7d4f-4d67-89f5-c636ba248e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = load_dataset(\"squad_v2\")\n",
    "\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "\n",
    "contexts_df = pd.DataFrame(np.unique(df['context']),columns=['context'])\n",
    "contexts_df.to_csv('contexts.csv')\n",
    "\n",
    "questions_df = df[['question']]\n",
    "answers_df = pd.DataFrame(['' if len(d['text'])==0 else d['text'][0] for d in df['answers']])\n",
    "answers_df.columns = ['answer']\n",
    "qa_df = pd.concat([questions_df,answers_df],axis=1)\n",
    "qa_df.to_csv('qa.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c0d4e8-791f-4cc1-ada8-8b803f1f3aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583f2a7e-1c8a-4026-875f-b235d07950cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('qa.csv',index_col=0)\n",
    "#df = pd.read_csv('qa.csv',index_col=0)\n",
    "\n",
    "docs = pd.DataFrame(np.unique(df['question']),columns=['question'])['question'][0:250]\n",
    "#docs = pd.DataFrame(np.unique(df['context']),columns=['context'])['context'][0:100]\n",
    "tokens_ = [docs.iloc[c].split(' ') for c in np.array(range(0,len(docs),1))]\n",
    "token_lengths = [len(t) for t in tokens_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c398bf-18a3-4db0-90bb-91379df1dd54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31475804-148e-4ab3-9dc2-de83785d8de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = np.random.choice(df['question'].values, 250, replace=False)\n",
    "encodings = [model.encode(q) for q in questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfff8cf-2040-44c4-b21e-94cb9f9b1fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "cosine_scores = util.cos_sim(encodings, encodings)\n",
    "print(type(cosine_scores))\n",
    "print(cosine_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6028b30f-2c7f-4656-88a5-49de4e0f7840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_centroids(data, labels):\n",
    "    # Calculate number of clusters\n",
    "    n_clusters = len(np.unique(labels))\n",
    "  \n",
    "    # Create empty centroid array\n",
    "    centroids = np.zeros((n_clusters, data.shape[1]))\n",
    "    \n",
    "    # Get indices of each cluster \n",
    "    for i in range(n_clusters):\n",
    "        indices = np.where(labels == i)[0]\n",
    "        \n",
    "        # Calculate mean of each cluster and store it as centroid\n",
    "        centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
    "    \n",
    "    return centroids\n",
    "\n",
    "def bcss_tss_ratio(X, cluster_centers):\n",
    "\n",
    "    # Computing Within Cluster Sum of Squares (WCSS)\n",
    "    wcss = np.sum([np.nansum((x - cluster_centers[i]) ** 2) for i in range(len(cluster_centers)) for x in X[labels == i]])\n",
    "\n",
    "    # Computing Between Cluster Sum of Squares (BCSS)\n",
    "    bcss = np.sum([np.nansum((x - center) ** 2) for center in cluster_centers for x in X])\n",
    "\n",
    "    # Computing Total Sum of Squares (TSS)\n",
    "    tss = np.sum([np.nansum((x - np.nanmean(X)) ** 2) for x in X])\n",
    "\n",
    "    # Computing the Ratio of WCSS to TSS\n",
    "    wcss_tss_ratio = wcss/tss\n",
    "\n",
    "    # Computing the Ratio of BCSS to TSS\n",
    "    bcss_tss_ratio = bcss/tss\n",
    "\n",
    "    #return wcss_tss_ratio, bcss_tss_ratio\n",
    "    return bcss_tss_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1a7f99-9d30-415b-9304-b4ed026569a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19284\\1002961604.py:13: RuntimeWarning: Mean of empty slice\n",
      "  centroids[i] = np.nanmean(data.iloc[indices], axis = 0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e</th>\n",
       "      <th>m</th>\n",
       "      <th>clusters</th>\n",
       "      <th>labels</th>\n",
       "      <th>centroids</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1.3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "      <td>[[0.07390175759792328, -0.0022267112508416176,...</td>\n",
       "      <td>250.069166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1.3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>[0, 0, 1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "      <td>[[0.7631099820137024, 0.7631101012229919, 0.11...</td>\n",
       "      <td>2000.017389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>[0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, ...</td>\n",
       "      <td>[[0.7631099820137024, 0.7631101012229919, 0.11...</td>\n",
       "      <td>60249.946573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[[0.9999998807907104, 0.5262200832366943, 0.15...</td>\n",
       "      <td>62500.033448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[[0.9999998807907104, 0.5262200832366943, 0.15...</td>\n",
       "      <td>62500.033448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[[0.9999998807907104, 0.5262200832366943, 0.15...</td>\n",
       "      <td>62500.033448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[[0.9999998807907104, 0.5262200832366943, 0.15...</td>\n",
       "      <td>62500.033448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[[0.9999998807907104, 0.5262200832366943, 0.15...</td>\n",
       "      <td>62500.033448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      e  m  clusters                                             labels  \\\n",
       "57  1.3  3         2  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...   \n",
       "56  1.3  2         9  [0, 0, 1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -...   \n",
       "55  1.3  1       241  [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, ...   \n",
       "0   0.1  1       250  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "11  0.2  1       250  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "22  0.3  1       250  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "33  0.5  1       250  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "44  0.8  1       250  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "\n",
       "                                            centroids         ratio  \n",
       "57  [[0.07390175759792328, -0.0022267112508416176,...    250.069166  \n",
       "56  [[0.7631099820137024, 0.7631101012229919, 0.11...   2000.017389  \n",
       "55  [[0.7631099820137024, 0.7631101012229919, 0.11...  60249.946573  \n",
       "0   [[0.9999998807907104, 0.5262200832366943, 0.15...  62500.033448  \n",
       "11  [[0.9999998807907104, 0.5262200832366943, 0.15...  62500.033448  \n",
       "22  [[0.9999998807907104, 0.5262200832366943, 0.15...  62500.033448  \n",
       "33  [[0.9999998807907104, 0.5262200832366943, 0.15...  62500.033448  \n",
       "44  [[0.9999998807907104, 0.5262200832366943, 0.15...  62500.033448  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "label_sets = []\n",
    "\n",
    "chosen = pd.DataFrame(cosine_scores)\n",
    "\n",
    "for e in np.array([1,2,3,5,8,13])/10:\n",
    "    for m in np.array([1,2,3,5,8,13,21,34,55,89,144]):\n",
    "        #print(e)\n",
    "        model_DB = DBSCAN(eps = e, min_samples = m, metric = 'euclidean').fit(chosen)\n",
    "        labels = model_DB.labels_\n",
    "        centroids = derive_centroids(chosen,labels)\n",
    "        label_sets.append([e,m,len(np.unique(labels)),labels,centroids,bcss_tss_ratio(chosen,centroids)])\n",
    "        \n",
    "#sizes = [len(np.unique(l)) for l in label_sets]\n",
    "#pd.DataFrame(sizes).hist()        \n",
    "\n",
    "results = pd.DataFrame(label_sets)\n",
    "results.columns = ['e','m','clusters','labels','centroids','ratio']\n",
    "results.query('ratio > 0').sort_values('clusters',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6102004b-d042-4117-893a-bf8993af1149",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "questions = pd.DataFrame(docs)\n",
    "questions['cluster'] = results.iloc[58]['labels']\n",
    "\"\"\"\n",
    "chosen = 56\n",
    "results_df = pd.DataFrame(questions,columns=['question'])\n",
    "results_df['cluster'] = results.iloc[chosen]['labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e4c0b5-96fd-4b25-a698-6016741323b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many photos does the CD-ROM XA hold?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many minutes does a Super Audio CD hold?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How much did the percentage of households with...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who was Victoria's eighth child?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Article IV, Section Three allows Congress to d...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>What term is used by the UNO to divide groups ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>What species group are annelids' muscle contro...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>On What date was Pope Paul VI born?</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Which ingredient gives beer its flavor?</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Do children or adolescents define themselves b...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  cluster\n",
       "0             How many photos does the CD-ROM XA hold?        0\n",
       "1         How many minutes does a Super Audio CD hold?        0\n",
       "2    How much did the percentage of households with...        1\n",
       "3                    Who was Victoria's eighth child?         2\n",
       "4    Article IV, Section Three allows Congress to d...       -1\n",
       "..                                                 ...      ...\n",
       "245  What term is used by the UNO to divide groups ...       -1\n",
       "246  What species group are annelids' muscle contro...       -1\n",
       "247                On What date was Pope Paul VI born?        6\n",
       "248            Which ingredient gives beer its flavor?       -1\n",
       "249  Do children or adolescents define themselves b...       -1\n",
       "\n",
       "[250 rows x 2 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88de9d53-d999-46c4-b1c9-7dc3b47a0b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28530b89-c6ac-4305-a54a-d8b3f2b003ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster:  0\n",
      "['How many photos does the CD-ROM XA hold?'\n",
      " 'How many minutes does a Super Audio CD hold?']\n",
      "cluster:  1\n",
      "['How much bandwidth did YouTube consume in 2014?'\n",
      " 'How much did the percentage of households with access to the internet decrease between 2003 and 2013?']\n",
      "cluster:  2\n",
      "[\"Who was Victoria's eighth child? \"\n",
      " 'Who did Victoria blame for her poor relationship with her mother?']\n",
      "cluster:  3\n",
      "['What measures the amount of light entering the eye?'\n",
      " 'Which devices do not produce light by luminescence?']\n",
      "cluster:  4\n",
      "['In medical diagnosis, what is pain considered?'\n",
      " 'What is pain medicine often under disciplines like physiatry, neurology, etc?'\n",
      " 'What is the term for nociceptors which respond to more than one type of stimuli?']\n",
      "cluster:  5\n",
      "['Who is the federal government in Germany governed by?'\n",
      " 'What is the Swedish term for government?']\n",
      "cluster:  6\n",
      "['Who was required to sign a decree declaring Paul VI a saint?'\n",
      " 'On What date was Pope Paul VI born?']\n",
      "cluster:  7\n",
      "['What is neutrophils the result of?' 'What surrounds the lymphocytes?']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dba390-9a26-49e8-9d31-e24516726ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea36436-22e5-49fa-94cd-0b89c97e90cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#from nltk.corpus import wordnet as wn\n",
    "#from nltk.corpus import wordnet_ic\n",
    "\n",
    "dog=wn.synsets('dog', pos=wn.NOUN)[0] #get the first noun synonym of the word \"dog\"\n",
    "print(dog)\n",
    "cat=wn.synsets('cat', pos=wn.NOUN)[0]\n",
    "rose=wn.synsets('rose', pos=wn.NOUN)[0]\n",
    "flower=wn.synsets('flower', pos=wn.NOUN)[0]\n",
    "\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat') #load the brown corpus to compute the IC\n",
    "\n",
    "rose.res_similarity(flower, brown_ic)\n",
    "rose.res_similarity(dog, brown_ic)\n",
    "cat.res_similarity(dog, brown_ic)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b93a18b-b684-4abb-aa2b-ca99e853160c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc3586a-674d-449e-904a-e77a93bf78f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c2d95e-6add-4f8d-90b0-f23357dc642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#contexts = pd.read_csv('contexts.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8713f7c2-70ed-438b-a202-0b23284eb1c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef5e9a9-9b1f-4239-84c5-f653ba6966a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b882d2f-2c85-441d-9768-6b181d3b98f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c7cf50-d216-4a6a-9f87-3ac94aa7bb3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fd8391-e547-4a50-b836-89897db85ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7f1bab-f8f9-40ac-9698-3821ffaa4934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce634ef-1c61-437e-8cf8-60b5457f5ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "cluster_topics = []\n",
    "import numpy as np\n",
    "for c in np.array(range(0,len(np.unique(questions_df['cluster'])),1)):\n",
    "    print(c)\n",
    "    docs = questions_df[questions_df['cluster']==c]['question'].values\n",
    "\n",
    "    vocab = createVocab_lemma(docs)\n",
    "\n",
    "    #Compute document term matrix as well idf for each term \n",
    "\n",
    "    termDict={}\n",
    "\n",
    "    docsTFMat = np.zeros((len(docs),len(vocab)))\n",
    "\n",
    "    docsIdfMat = np.zeros((len(vocab),len(docs)))\n",
    "\n",
    "    docTermDf = pd.DataFrame(docsTFMat ,columns=sorted(vocab.keys()))\n",
    "    docCount=0\n",
    "    for doc in docs:\n",
    "        doc= doc.translate(str.maketrans('', '', string.punctuation))\n",
    "        word_synsets = [wordnet.synsets(word) for word in word_tokenize(doc.lower())]\n",
    "        for word_synset in word_synsets:\n",
    "            if (word_synset):\n",
    "                for lemma in word_synset[0].lemmas():\n",
    "                    if(lemma.name() in vocab.keys()):\n",
    "                        docTermDf[lemma.name()][docCount] = docTermDf[lemma.name()][docCount] +1\n",
    "\n",
    "        docCount = docCount +1\n",
    "\n",
    "    feature_names = sorted(vocab.keys())\n",
    "    docList=np.array(range(0,len(docs),1))\n",
    "\n",
    "    #Computed idf for each word in vocab\n",
    "    idfDict={}\n",
    "\n",
    "    for column in docTermDf.columns:\n",
    "        idfDict[column]= np.log((len(docs) +1 )/(1+ (docTermDf[column] != 0).sum()))+1\n",
    "\n",
    "    #compute tf.idf matrix\n",
    "    docsTfIdfMat = np.zeros((len(docs),len(vocab)))\n",
    "    docTfIdfDf = pd.DataFrame(docsTfIdfMat ,columns=sorted(vocab.keys()))\n",
    "\n",
    "    docCount = 0\n",
    "    for doc in docs:\n",
    "        for key in idfDict.keys():\n",
    "            docTfIdfDf[key][docCount] = docTermDf[key][docCount] * idfDict[key]\n",
    "        docCount = docCount +1 \n",
    "\n",
    "    skDocsTfIdfdf = pd.DataFrame(docTfIdfDf, index=sorted(docList), columns=feature_names)\n",
    "    cluster_topics.append(find_most_common_words(skDocsTfIdfdf,.5))\n",
    "    \"\"\"\n",
    "    model = Top2Vec(subset.flatten(), embedding_model='universal-sentence-encoder')\n",
    "    topic_sizes, topic_nums = model.get_topic_sizes()\n",
    "    topic_words, word_scores, topic_nums = model.get_topics(model.get_num_topics())\n",
    "    \n",
    "    print(subset)\n",
    "    print(topic_words)\n",
    "    cluster_topics.append([subset,topic_sizes,topic_words, word_scores, topic_nums])\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a77582-6c4c-46cb-a3af-4d191d71dfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count = results.iloc[chosen]['clusters']\n",
    "#set_ = questions.query('cluster >= 0').sort_values(by='cluster')\n",
    "questions_df = results_df.query('cluster >= 0').sort_values(by='cluster')\n",
    "for c in np.array(range(0,count-1,1)):\n",
    "    print('cluster: ', c)\n",
    "    #print(set_[set_['cluster']==c]['question'].values)\n",
    "    print(questions_df[questions_df['cluster']==c]['question'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52008abc-306e-45bf-9ade-ea2ef8dadfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "hold       2.000000\n",
      "many       2.000000\n",
      "audio      1.405465\n",
      "minutes    1.405465\n",
      "super      1.405465\n",
      "dtype: float64\n",
      "[['How many photos does the CD-ROM XA hold?']\n",
      " ['How many minutes does a Super Audio CD hold?']]\n",
      "1\n",
      "much          2.000000\n",
      "access        1.405465\n",
      "bandwidth     1.405465\n",
      "between       1.405465\n",
      "consume       1.405465\n",
      "decrease      1.405465\n",
      "percentage    1.405465\n",
      "in            1.405465\n",
      "internet      1.405465\n",
      "dtype: float64\n",
      "[['How much bandwidth did YouTube consume in 2014?']\n",
      " ['How much did the percentage of households with access to the internet decrease between 2003 and 2013?']]\n",
      "2\n",
      "blame           1.405465\n",
      "child           1.405465\n",
      "eighth          1.405465\n",
      "mother          1.405465\n",
      "poor            1.405465\n",
      "relationship    1.405465\n",
      "dtype: float64\n",
      "[[\"Who was Victoria's eighth child? \"]\n",
      " ['Who did Victoria blame for her poor relationship with her mother?']]\n",
      "3\n",
      "light    2.0\n",
      "dtype: float64\n",
      "[['What measures the amount of light entering the eye?']\n",
      " ['Which devices do not produce light by luminescence?']]\n",
      "4\n",
      "pain         2.575364\n",
      "often        1.693147\n",
      "medical      1.693147\n",
      "one          1.693147\n",
      "diagnosis    1.693147\n",
      "term         1.693147\n",
      "neurology    1.693147\n",
      "respond      1.693147\n",
      "medicine     1.693147\n",
      "like         1.693147\n",
      "in           1.693147\n",
      "type         1.693147\n",
      "under        1.693147\n",
      "dtype: float64\n",
      "[['In medical diagnosis, what is pain considered?']\n",
      " ['What is pain medicine often under disciplines like physiatry, neurology, etc?']\n",
      " ['What is the term for nociceptors which respond to more than one type of stimuli?']]\n",
      "5\n",
      "government    2.000000\n",
      "by            1.405465\n",
      "governed      1.405465\n",
      "in            1.405465\n",
      "term          1.405465\n",
      "dtype: float64\n",
      "[['Who is the federal government in Germany governed by?']\n",
      " ['What is the Swedish term for government?']]\n",
      "6\n",
      "date      1.405465\n",
      "decree    1.405465\n",
      "on        1.405465\n",
      "pope      1.405465\n",
      "saint     1.405465\n",
      "sign      1.405465\n",
      "dtype: float64\n",
      "[['Who was required to sign a decree declaring Paul VI a saint?']\n",
      " ['On What date was Pope Paul VI born?']]\n",
      "7\n",
      "result    1.405465\n",
      "dtype: float64\n",
      "[['What is neutrophils the result of?']\n",
      " ['What surrounds the lymphocytes?']]\n"
     ]
    }
   ],
   "source": [
    "for c in np.array(range(0,len(np.unique(questions_df['cluster'])),1)):\n",
    "    print(c)\n",
    "    print(cluster_topics[c])\n",
    "    #print(questions[c])\n",
    "    docs = questions_df[questions_df['cluster']==c][['question']].values\n",
    "    print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03fd24b-10c3-46b5-a59d-a49fcb853005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fd72ee-7a90-485f-81ae-809196c6d258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19914afa-a486-4418-96f9-d3755f2aa067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2890de63-faef-4703-9b3b-6336d3650959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cdefb8-2462-452f-b051-f754efa1ad2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
