{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71f4068-4ffa-4a51-82ae-9c24e2676c99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab5e65a2-b7bb-493b-b762-3bf4108295b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to write data to connection IPv4Address(('192.168.3.224', 7687)) (IPv4Address(('192.168.3.224', 7687)))\n"
     ]
    }
   ],
   "source": [
    "# CQL to create states as nodes\n",
    "# CQL to query the difference in population from a given state to all the other states.\n",
    "# Create relationships between the states as defined above (i.e. region and the binary classifications).\n",
    "# Use the above states_df to read the data (i.e. please don't repeatedly write out state and/or field names).\n",
    "\n",
    "\n",
    "# import the neo4j driver for Python\n",
    "from neo4j import GraphDatabase\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Database Credentials\n",
    "uri = \"bolt://192.168.3.224:7687\"\n",
    "userName = \"neo4j\"\n",
    "password = \"senator-index-nebula-silver-zero-9434\"\n",
    "\n",
    "# Connect to the neo4j database server\n",
    "graphDB_Driver = GraphDatabase.driver(uri, auth=(userName, password))\n",
    "\n",
    "regions = {'Maine': 'Northeast', 'Massachusetts': 'Northeast', 'Rhode Island': 'Northeast', 'Connecticut': 'Northeast', 'New Hampshire': 'Northeast', 'Vermont': 'Northeast', 'New York': 'Northeast', 'Pennsylvania': 'Northeast', 'New Jersey': 'Northeast', 'Delaware': 'Northeast', 'Maryland': 'Northeast', 'West Virginia': 'Southeast', 'Virginia': 'Southeast', 'Kentucky': 'Southeast', 'Tennessee': 'Southeast', 'North Carolina': 'Southeast', 'South Carolina': 'Southeast', 'Georgia': 'Southeast', 'Alabama': 'Southeast', 'Mississippi': 'Southeast', 'Arkansas': 'Southeast', 'Louisiana': 'Southeast', 'Florida': 'Southeast', 'Ohio': 'Midwest', 'Indiana': 'Midwest', 'Michigan': 'Midwest', 'Illinois': 'Midwest', 'Missouri': 'Midwest', 'Wisconsin': 'Midwest', 'Minnesota': 'Midwest', 'Iowa': 'Midwest', 'Kansas': 'Midwest', 'Nebraska': 'Midwest', 'South Dakota': 'Midwest', 'North Dakota': 'Midwest', 'Texas': 'Southwest', 'Oklahoma': 'Southwest', 'New Mexico': 'Southwest', 'Arizona': 'Southwest', 'Colorado': 'West', 'Wyoming': 'West', 'Montana': 'West', 'Idaho': 'West', 'Washington': 'West', 'Oregon': 'West', 'Utah': 'West', 'Nevada': 'West', 'California': 'West', 'Alaska': 'West', 'Hawaii': 'West'}\n",
    "\n",
    "# Function to create nodes\n",
    "def create_nodes(states_df):\n",
    "    queries = []\n",
    "    #delete everything first\n",
    "    cqlCreate = \"MATCH (n) DETACH DELETE n\"\n",
    "    with graphDB_Driver.session() as graphDB_Session:\n",
    "            graphDB_Session.run(cqlCreate)\n",
    "    # Create states as nodes\n",
    "    for i, row in states_df.iterrows():\n",
    "        state = row['States']\n",
    "        poverty = row['Poverty']\n",
    "        infant_mort = row['Infant Mort']\n",
    "        white = row['White']\n",
    "        crime = row['Crime']\n",
    "        doctors = row['Doctors']\n",
    "        traf_deaths = row['Traf Deaths']\n",
    "        university = row['University']\n",
    "        unemployed = row['Unemployed']\n",
    "        income = row['Income']\n",
    "        population = row['Population']\n",
    "        region = row['region']\n",
    "  \n",
    "        cqlCreate = \"CREATE (\" + state.replace(\" \", \"\") + \":state { name: '\" + state + f\"', poverty: {poverty}\" + f\", infant_mort: {infant_mort}\" + f\", white: {white}\" + f\", crime: {crime}\" +\\\n",
    "        f\", doctors: {doctors}\" + f\", traf_deaths: {traf_deaths}\"  + f\", university: {university}\" + f\", unemployed: {unemployed}\" + f\", income: {income}\" + f\", population: {population}\" + f\", region: '{region}'\" +\\\n",
    "        \"})\"\n",
    "        \n",
    "        queries.append(cqlCreate)\n",
    "                \n",
    "        # Execute the CQL query\n",
    "        with graphDB_Driver.session() as graphDB_Session:\n",
    "            graphDB_Session.run(cqlCreate)\n",
    "            \n",
    "    # Create region nodes\n",
    "    #{'Midwest', 'Northeast', 'Southeast', 'Southwest', 'West'}\n",
    "    cqlCreate = \"CREATE (Midwest:region {name: 'Midwest'}), (Northeast:region {name: 'Northeast'}), (Southeast:region {name: 'Southeast'}), (Southwest:region {name: 'Southwest'}), (West:region {name: 'West'})\"\n",
    "    with graphDB_Driver.session() as graphDB_Session:\n",
    "        graphDB_Session.run(cqlCreate)\n",
    "        \n",
    "    # Create nodes for factors\n",
    "    cqlCreate = \"CREATE (poverty:factor {name: 'Poverty'}), (infant_mort:factor {name: 'Infant Mort'}), (white:factor {name: 'White'}), (crime:factor {name: 'Crime'}), (doctors:factor {name: 'Doctors'}), (traf_deaths:factor {name: 'Traf Deaths'}), (university:factor {name: 'University'}), (unemployed:factor {name: 'Unemployed'}), (income:factor {name: 'Income'}), (population:factor {name: 'Population'})\"\n",
    "    with graphDB_Driver.session() as graphDB_Session:\n",
    "        graphDB_Session.run(cqlCreate)\n",
    "                \n",
    "# Function to create relationships between the states, factors, region\n",
    "def create_relationships(states_df):\n",
    "    cqlCreate = \"\"\n",
    "    # Create state and region relationships\n",
    "    for i, row in states_df.iterrows():\n",
    "        state = row['States']\n",
    "        region = row['region']\n",
    "        cqlCreate = f\"MATCH (x:state {{name: '{state}'}}), (y:region {{name: '{region}'}}) CREATE (x)-[:part_of]->(y)\"\n",
    "        with graphDB_Driver.session() as graphDB_Session:\n",
    "            graphDB_Session.run(cqlCreate)\n",
    "    \n",
    "    cqlCreate = \"\"\n",
    "    # Create state and factor relationships\n",
    "    for i, row in states_df.iterrows():\n",
    "        state = row['States']\n",
    "        for column in states_df.columns:\n",
    "            if column not in [\"States\", \"region\"]:\n",
    "                cqlCreate = f\"MATCH (x:state {{name: '{state}'}}), (y:factor {{name: '{column}'}}) CREATE (x)-[:has {{value: {row[column]}}}]->(y)\"\n",
    "                with graphDB_Driver.session() as graphDB_Session:\n",
    "                    graphDB_Session.run(cqlCreate)\n",
    "                    \n",
    "# Rewritten findPageRank function\n",
    "# Rewritten findPageRank function\n",
    "def findPageRank(query, pages):\n",
    "    # Execute the CQL query\n",
    "    with graphDB_Driver.session() as graphDB_Session:\n",
    "        results = graphDB_Session.run(query)\n",
    "\n",
    "        # Create link matrix\n",
    "        factor_nodes = []\n",
    "        region_nodes = []\n",
    "        for result in results:\n",
    "            nodes = result.values()\n",
    "            for i in range(len(nodes)):\n",
    "                if nodes[i]['name'] in pages:\n",
    "                    region_nodes.append(nodes[i]['name'])\n",
    "                else:\n",
    "                    factor_nodes.append(nodes[i]['name'])\n",
    "\n",
    "        # Create link matrix with appropriate number of rows and columns\n",
    "        linkmatrix = np.zeros((len(region_nodes), len(factor_nodes)))\n",
    "\n",
    "        # Populate linkmatrix with values from query results\n",
    "        for result in results:\n",
    "            nodes = result.values()\n",
    "            for i in range(len(nodes)-1):\n",
    "                if nodes[i]['name'] in region_nodes and nodes[i+1]['name'] in factor_nodes:\n",
    "                    linkmatrix[region_nodes.index(nodes[i]['name'])][factor_nodes.index(nodes[i+1]['name'])] = 1\n",
    "\n",
    "        eigval, eigvector= np.linalg.eig(linkmatrix)\n",
    "        dominant_eigval = np.abs(eigval).max()\n",
    "        PageRank= np.where(eigval == dominant_eigval)\n",
    "        print(\"The most important node is %s\"% str(region_nodes[PageRank[0][0]]))\n",
    "\n",
    "\n",
    "# Main\n",
    "if __name__ == '__main__':\n",
    "    # Read the data\n",
    "    states_df = pd.read_csv('https://raw.githubusercontent.com/thistleknot/python-ml/master/data/raw/states.csv')\n",
    "    \n",
    "    mads = stats.median_abs_deviation(states_df.iloc[:,1:11])\n",
    "    stds = np.std(states_df.iloc[:,1:11])\n",
    "    \n",
    "    medians_df = pd.DataFrame(states_df.iloc[:,1:11].median()).T\n",
    "    mads_df = pd.DataFrame([mads],columns=states_df.columns[1:11])\n",
    "    means_df = pd.DataFrame(states_df.iloc[:,1:11].mean()).T\n",
    "    stds_df = pd.DataFrame([stds],columns=states_df.columns[1:11])\n",
    "   \n",
    "    states_df['region'] = [regions[s] for s in states_df['States'].values]   \n",
    "    \n",
    "    # Create states as nodes\n",
    "    create_nodes(states_df)\n",
    "\n",
    "    create_relationships(states_df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8edadb10-55c2-450e-83cb-4aea83ed5cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#states_df[['region']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "2b7549e9-dd7d-40cc-9a1d-072430b819c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Last 2 dimensions of the array must be square",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [311]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mcall \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mMATCH (s:state)-[:has]->(f:factor) WITH avg(s.poverty) as poverty return poverty}\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124mmatch (s:state)-[:has]->(f:factor),(s:state)-[:part_of]->(r:region)\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124mwhere s.poverty > poverty\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124mreturn s, f, r\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      5\u001b[0m pages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(regions\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m----> 6\u001b[0m \u001b[43mfindPageRank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpages\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [310]\u001b[0m, in \u001b[0;36mfindPageRank\u001b[1;34m(query, pages)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m nodes[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m region_nodes \u001b[38;5;129;01mand\u001b[39;00m nodes[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m factor_nodes:\n\u001b[0;32m    111\u001b[0m             linkmatrix[region_nodes\u001b[38;5;241m.\u001b[39mindex(nodes[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m])][factor_nodes\u001b[38;5;241m.\u001b[39mindex(nodes[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m])] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 113\u001b[0m eigval, eigvector\u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinkmatrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m dominant_eigval \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(eigval)\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m    115\u001b[0m PageRank\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(eigval \u001b[38;5;241m==\u001b[39m dominant_eigval)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36meig\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\numpy\\linalg\\linalg.py:1311\u001b[0m, in \u001b[0;36meig\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m   1309\u001b[0m a, wrap \u001b[38;5;241m=\u001b[39m _makearray(a)\n\u001b[0;32m   1310\u001b[0m _assert_stacked_2d(a)\n\u001b[1;32m-> 1311\u001b[0m \u001b[43m_assert_stacked_square\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1312\u001b[0m _assert_finite(a)\n\u001b[0;32m   1313\u001b[0m t, result_t \u001b[38;5;241m=\u001b[39m _commonType(a)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\numpy\\linalg\\linalg.py:204\u001b[0m, in \u001b[0;36m_assert_stacked_square\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    202\u001b[0m m, n \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;241m!=\u001b[39m n:\n\u001b[1;32m--> 204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLast 2 dimensions of the array must be square\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Last 2 dimensions of the array must be square"
     ]
    }
   ],
   "source": [
    "\n",
    "query = \"\"\"call {MATCH (s:state)-[:has]->(f:factor) WITH avg(s.poverty) as poverty return poverty}\n",
    "match (s:state)-[:has]->(f:factor),(s:state)-[:part_of]->(r:region)\n",
    "where s.poverty > poverty\n",
    "return s, f, r\"\"\"\n",
    "pages = list(regions.keys())\n",
    "findPageRank(query, pages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b8b7a0-1469-43fb-adb8-9e69634d69de",
   "metadata": {},
   "outputs": [],
   "source": [
    "(means_df['White'].values[0] + stds_df['White'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c465d41c-3acb-4c1e-b6fd-e0aaa95689d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_df['White']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efdea34-5183-40a9-a2f3-916c41c66d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "(states_df['White'] >= (means_df['White'].values[0] + stds_df['White'].values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb25ac8-5d49-46bb-a67a-1a541677da48",
   "metadata": {},
   "outputs": [],
   "source": [
    "(states_df['University'] >= (states_df['University'].median()+mads_df['University'].values[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a36648-7b7e-4769-9c97-1208b794465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabc9ae2-5291-4d78-aa81-cc039190d7d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
