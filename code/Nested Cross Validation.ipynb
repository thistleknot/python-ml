{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92de849c-fc6a-4fb9-ac6f-186d17b2b923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatic nested cross-validation of regression of 'Linear Regression using Step Forward Feature Selection' contrasted with 'Elastic Net' using pipelines as well as ZCA whitening to scale variables..\n",
    "\n",
    "#https://machinelearningmastery.com/nested-cross-validation-for-machine-learning-with-python/\n",
    "#https://machinelearningmastery.com/elastic-net-regression-in-python/\n",
    "#https://github.com/rasbt/mlxtend/issues/41\n",
    "#https://github.com/rasbt/mlxtend/issues/69\n",
    "#https://stackoverflow.com/questions/53252156/standardscaler-with-pipelines-and-gridsearchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbb1adca-d35a-4671-9667-bffad54974e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "from numpy import arange\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from random import sample\n",
    "\n",
    "import random\n",
    "\n",
    "import re\n",
    "\n",
    "#from sklearn.datasets import make_classification\n",
    "from sklearn import linear_model\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc685d3a-564a-4092-a219-9eef11441886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# ------------------------------------\n",
    "# file: zca.py\n",
    "# date: Thu May 21 15:47 2015\n",
    "# author:\n",
    "# Maarten Versteegh\n",
    "# github.com/mwv\n",
    "# maartenversteegh AT gmail DOT com\n",
    "#\n",
    "# Licensed under GPLv3\n",
    "# ------------------------------------\n",
    "\"\"\"zca: ZCA whitening with a sklearn-like interface\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.utils import check_array, as_float_array\n",
    "\n",
    "class ZCA(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, regularization=1e-6, copy=False):\n",
    "        self.regularization = regularization\n",
    "        self.copy = copy\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Compute the mean, whitening and dewhitening matrices.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like with shape [n_samples, n_features]\n",
    "            The data used to compute the mean, whitening and dewhitening\n",
    "            matrices.\n",
    "        \"\"\"\n",
    "        X = check_array(X, accept_sparse=None, copy=self.copy,\n",
    "                        ensure_2d=True)\n",
    "        X = as_float_array(X, copy=self.copy)\n",
    "        self.mean_ = X.mean(axis=0)\n",
    "        X_ = X - self.mean_\n",
    "        cov = np.dot(X_.T, X_) / (X_.shape[0]-1)\n",
    "        U, S, _ = linalg.svd(cov)\n",
    "        s = np.sqrt(S.clip(self.regularization))\n",
    "        s_inv = np.diag(1./s)\n",
    "        s = np.diag(s)\n",
    "        self.whiten_ = np.dot(np.dot(U, s_inv), U.T)\n",
    "        self.dewhiten_ = np.dot(np.dot(U, s), U.T)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, copy=None):\n",
    "        \"\"\"Perform ZCA whitening\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like with shape [n_samples, n_features]\n",
    "            The data to whiten along the features axis.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, 'mean_')\n",
    "        X = as_float_array(X, copy=self.copy)\n",
    "        return np.dot(X - self.mean_, self.whiten_.T)\n",
    "\n",
    "    def inverse_transform(self, X, copy=None):\n",
    "        \"\"\"Undo the ZCA transform and rotate back to the original\n",
    "        representation\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like with shape [n_samples, n_features]\n",
    "            The data to rotate back.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, 'mean_')\n",
    "        X = as_float_array(X, copy=self.copy)\n",
    "        return np.dot(X, self.dewhiten_) + self.mean_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53dae0be-aa5b-41a6-ac79-03045466367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    df = pd.read_csv(\"https://raw.githubusercontent.com/thistleknot/Python-Stock/master/data/raw/states.csv\").set_index('States')\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a98ab490-94f1-49b3-97f0-d4d0e3e331c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "independent = 'Poverty'\n",
    "outer_k = 10\n",
    "inner_k = 10\n",
    "random_st = random.sample(list(np.arange(0,10,1)),1)[0]\n",
    "print(random_st)\n",
    "\n",
    "# configure the cross-validation procedure\n",
    "cv_inner = KFold(n_splits=inner_k, shuffle=True, random_state=random_st)\n",
    "cv_outer = KFold(n_splits=outer_k, shuffle=True, random_state=random_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f0f0f45-3357-492d-86de-7aabd366e6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "y = read_data()[[independent]]\n",
    "X = read_data()[(read_data().columns).difference([independent]).values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a486e8c-f677-4363-9c23-b5af018984de",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbd4a0d6-a64f-42a7-9d96-951381e3bed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c8ab64fb-89be-40c3-9ca9-cd3665261f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.11959562e-03  4.48151309e-03 -3.11204546e-04  2.38830513e-03\n",
      "  7.44896599e-08  6.29854278e-04  4.50184327e-03 -1.62534937e-03\n",
      " -3.62924054e-02]\n",
      "[-1.89849098e-03  3.84660107e-03 -2.73498343e-04  1.77463610e-01\n",
      "  6.77979869e-08  2.01048769e+00  5.74691096e-01  7.19957977e-02\n",
      " -4.79904187e-02]\n",
      "[-1.05293748e-03  1.54512845e-03 -2.84741120e-04 -3.97770678e-01\n",
      "  3.85962180e-08  4.15823982e-01  3.47371244e-01 -1.00772561e-01\n",
      " -1.38011535e-01]\n",
      "[ 3.97825928e-04  3.66528333e-03 -3.32627568e-04  0.00000000e+00\n",
      "  8.17126604e-08  0.00000000e+00  1.59696119e-01 -0.00000000e+00\n",
      " -6.29880719e-02]\n",
      "[ 2.03819990e-03  5.77465111e-03 -3.34100289e-04  1.99041139e-03\n",
      "  7.99484943e-08  8.22960475e-04  4.32081178e-03 -3.03706008e-03\n",
      " -3.43229831e-02]\n",
      "[ 1.34172989e-03  2.67440757e-03 -3.19084379e-04  0.00000000e+00\n",
      "  8.32421881e-08  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -5.42062977e-02]\n",
      "[ 1.53981622e-03  3.20085343e-03 -3.39259667e-04  0.00000000e+00\n",
      "  8.85301308e-08  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      " -5.56680970e-02]\n",
      "[ 1.98562796e-03  4.29254544e-03 -3.21158733e-04  2.62730734e-03\n",
      "  8.28654222e-08  8.55675640e-04  3.85552785e-03 -3.14851244e-03\n",
      " -3.50842292e-02]\n",
      "[ 1.92288244e-03  2.61162788e-03 -3.15185124e-04  1.49378042e-03\n",
      "  9.27456784e-08  8.38158806e-04  2.84558854e-03 -3.18218297e-03\n",
      " -3.00596527e-02]\n",
      "[ 2.20276223e-03  5.14820155e-03 -3.06868263e-04 -0.00000000e+00\n",
      "  8.09621541e-08  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      " -3.04805985e-02]\n",
      "accuracy: 2.917 (2.609)\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, random_state=1,shuffle=True)\n",
    "ratios = arange(0, 1, 0.1)\n",
    "alphas = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.0, 1.0, 10.0, 100.0]\n",
    "model = ElasticNetCV(l1_ratio=ratios, alphas=alphas, cv=cv, n_jobs=-1)\n",
    "\n",
    "outer_results = list()\n",
    "\n",
    "# perform cross-validation procedure\n",
    "for train_ix, test_ix in cv_outer.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "\n",
    "    \n",
    "    pipe_ENet_Regressor = Pipeline([\n",
    "                #('scaler',  ZCA()),\n",
    "                ('ENet_Regressor', model)])\n",
    "\n",
    "    grid_params_ENet_Regressor = [{\n",
    "    }]\n",
    "\n",
    "\n",
    "    CV_ENet_regressor = GridSearchCV (estimator = pipe_ENet_Regressor,\n",
    "                                   param_grid = grid_params_ENet_Regressor,\n",
    "                                   #cv = cv,return_train_score=True, verbose=0, refit=True)\n",
    "                                   return_train_score=True, verbose=0, refit=True)\n",
    "\n",
    "    CV_ENet_regressor.fit(X_train, y_train)\n",
    "    \n",
    "    print(best_model.named_steps['ENet_Regressor'].coef_)\n",
    "    \n",
    "    #ypred=CV_ENet_regressor.predict(X_test)\n",
    "\n",
    "    best_model = CV_ENet_regressor.best_estimator_\n",
    "    yhat = best_model.predict(X_test)\n",
    "\n",
    "    # evaluate the model\n",
    "    acc = mean_squared_error(y_test, yhat,squared=True)\n",
    "    #cross_val_score(self.search, X, y, scoring='neg_mean_squared_error', cv=cv_outer, n_jobs=-1)\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    \n",
    "print('accuracy: %.3f (%.3f)' % (mean(outer_results), std(outer_results)))\n",
    "\n",
    "model_results.append(['Elastic',mean(outer_results), std(outer_results)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83edbfa2-7d8d-4032-bb17-15b6e5d85807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d2d6c96f-ab3d-4914-baf4-5590098c7628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Income', 'Infant Mort', 'Population', 'Unemployed'], dtype='object')\n",
      "Index(['Income', 'Infant Mort', 'Population', 'Unemployed', 'University',\n",
      "       'White'],\n",
      "      dtype='object')\n",
      "Index(['Income', 'Population', 'Unemployed', 'University', 'White'], dtype='object')\n",
      "Index(['Income', 'Population', 'Unemployed', 'White'], dtype='object')\n",
      "Index(['Income', 'Population', 'White'], dtype='object')\n",
      "Index(['Doctors', 'Income', 'Population', 'Traf Deaths', 'Unemployed'], dtype='object')\n",
      "Index(['Doctors', 'Income', 'Population', 'Traf Deaths', 'Unemployed',\n",
      "       'White'],\n",
      "      dtype='object')\n",
      "Index(['Crime', 'Income', 'Population', 'Traf Deaths', 'Unemployed'], dtype='object')\n",
      "Index(['Doctors', 'Income', 'Population', 'Traf Deaths', 'White'], dtype='object')\n",
      "Index(['Doctors', 'Income', 'Population', 'Traf Deaths', 'Unemployed',\n",
      "       'University', 'White'],\n",
      "      dtype='object')\n",
      "accuracy: 2.791 (2.876)\n"
     ]
    }
   ],
   "source": [
    "#linear\n",
    "\n",
    "cv = KFold(n_splits=2, random_state=1,shuffle=True)\n",
    "#model = ElasticNetCV(l1_ratio=0, alphas=[0], n_jobs=-1)\n",
    "model = LinearRegression()\n",
    "\n",
    "outer_results = list()\n",
    "\n",
    "class sfs_(SFS):        \n",
    "    def score(self):\n",
    "        return np.min(np.abs([self.subsets_[i]['avg_score'] for i in range(1,len(self.subsets_))]))*-1\n",
    "\n",
    "# perform cross-validation procedure\n",
    "for train_ix, test_ix in cv_outer.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "\n",
    "    sfs1 = sfs_(model, \n",
    "               k_features=len(X.columns),\n",
    "               forward=True, \n",
    "               floating=False, \n",
    "               scoring='neg_mean_squared_error',\n",
    "               cv=cv)\n",
    "\n",
    "    pipe = Pipeline([\n",
    "                    #('standardize', ZCA()),\n",
    "                     ('sfs', sfs1)#, \n",
    "                     #('lr', model)\n",
    "                    ])\n",
    "\n",
    "    param_grid = {\n",
    "      }\n",
    "\n",
    "    CV_Linear_regressor = GridSearchCV (estimator = pipe,\n",
    "                                   param_grid = param_grid,\n",
    "                                   #cv = cv,return_train_score=True, verbose=0, refit=True)\n",
    "                                   verbose=0, refit=True)\n",
    "\n",
    "    CV_Linear_regressor.fit(X_train, y_train)\n",
    "    \n",
    "    #ypred=CV_ENet_regressor.predict(X_test)\n",
    "\n",
    "    best_model = CV_Linear_regressor.best_estimator_\n",
    "    #plt.plot(pd.DataFrame(best_model.named_steps['sfs'].subsets_).loc['avg_score'])\n",
    "\n",
    "    bestSFS=X.columns[pd.Series(pd.DataFrame(best_model.named_steps['sfs'].subsets_).iloc[:,np.argmin(np.abs(pd.DataFrame(best_model.named_steps['sfs'].subsets_).loc['avg_score']))-1].feature_idx).to_list()]\n",
    "    print(bestSFS)\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X_train[bestSFS],y_train)\n",
    "    \n",
    "    #print(best_model.named_steps['lr'].coef_)\n",
    "    yhat = lm.predict(X_test[bestSFS])\n",
    "\n",
    "    # evaluate the model\n",
    "    acc = mean_squared_error(y_test, yhat,squared=True)\n",
    "    #cross_val_score(self.search, X, y, scoring='neg_mean_squared_error', cv=cv_outer, n_jobs=-1)\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    \n",
    "print('accuracy: %.3f (%.3f)' % (mean(outer_results), std(outer_results)))\n",
    "\n",
    "model_results.append(['Linear',mean(outer_results), std(outer_results)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b36bc60-3e3e-4ae9-84c0-414f860ad6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialFeatureSelector(cv=KFold(n_splits=2, random_state=1, shuffle=True),\n",
       "                          estimator=LinearRegression(), k_features=9,\n",
       "                          scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "\n",
    "sfs1 = SFS(model, \n",
    "           k_features=len(X.columns),\n",
    "           forward=True, \n",
    "           floating=False, \n",
    "           scoring='neg_mean_squared_error',\n",
    "           cv=cv)\n",
    "sfs1.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f73df3a7-8ed6-4422-b006-47e7c5e7de07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_calc_confidence',\n",
       " '_check_fitted',\n",
       " '_check_n_features',\n",
       " '_exclusion',\n",
       " '_get_param_names',\n",
       " '_get_params',\n",
       " '_get_tags',\n",
       " '_inclusion',\n",
       " '_more_tags',\n",
       " '_replace_estimator',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_required_parameters',\n",
       " '_set_params',\n",
       " '_validate_data',\n",
       " '_validate_names',\n",
       " 'fit',\n",
       " 'fit_transform',\n",
       " 'get_metric_dict',\n",
       " 'get_params',\n",
       " 'named_estimators',\n",
       " 'score',\n",
       " 'set_params',\n",
       " 'transform']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(sfs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a42c8b5e-8a77-4127-aacc-e369bbcbf711",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SequentialFeatureSelector' object has no attribute 'subsets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11700/3401831275.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msfs1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubsets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'SequentialFeatureSelector' object has no attribute 'subsets'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e0420229-cab6-4121-b936-4fdeadb94f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.7864075324941493"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a80f8f62-8052-4936-83b8-247643ec4bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs1.subsets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f082939-d7cf-4cfb-8976-621d18ab826a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Elastic', 2.6994513749989006, 2.9898170221851905],\n",
       " ['Linear', 2.7511100931572363, 3.0819880480803907]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0616733-9ecf-4b54-842d-f3a2f733e9a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "343cfe38-4912-4124-b273-c7783c61738d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  Elastic\n",
      "Accuracy: 2.277 (1.963)\n",
      "Model:  Linear\n",
      "Accuracy: 2.385 (1.936)\n",
      "Elastic\n"
     ]
    }
   ],
   "source": [
    "for s in range(0,len(model_results)):\n",
    "    print('Model: ', model_results[s][0])\n",
    "    print('Accuracy: %.3f (%.3f)' % (model_results[s][1], model_results[s][2]))\n",
    "\n",
    "#step 1\n",
    "best_model = [item[0] for item in model_results][np.argmin(np.abs([item[1] for item in model_results]))]\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d8de5bb-80cc-4fd0-8a4a-a99398958da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class model(ABC):\n",
    " \n",
    "    @abstractmethod\n",
    "    def setEstimators(self):\n",
    "        estimators_ENetCV = []\n",
    "        estimators_ENetCV.append(('standardize', ZCA()))\n",
    "\n",
    "        pass\n",
    "\"\"\"\n",
    "\n",
    "class regression_model():\n",
    "    def __init__(self,estimators):\n",
    "        self.estimators = estimators\n",
    "        \n",
    "        # define search\n",
    "        self.search = Pipeline(self.estimators)\n",
    "        # execute the nested cross-validation\n",
    "        self.scores = cross_val_score(self.search, X, y, scoring='neg_mean_squared_error', cv=cv_outer, n_jobs=-1)\n",
    "        # report performance\n",
    "        self.score = [(mean(self.scores), std(self.scores))]\n",
    "        \n",
    "    def score(self):\n",
    "        \n",
    "        return(self.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536149b2-1c2d-4693-a1ed-727fed9989ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89602861-d308-493a-81d0-56f81882fd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#elastic\n",
    "\n",
    "# define the model\n",
    "\n",
    "estimators_ENetCV = []\n",
    "estimators_ENetCV.append(('standardize', ZCA()))\n",
    "model = ElasticNet()\n",
    "grid = dict()\n",
    "grid['alpha'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.0, 1.0, 10.0, 100.0]\n",
    "#grid['n_alphas'] = [10]\n",
    "grid['l1_ratio'] = arange(0, 1, 0.1)\n",
    "search = GridSearchCV(model, grid, scoring='neg_mean_squared_error', n_jobs=1, cv=cv_inner, refit=True)\n",
    "#estimators_ENetCV.append(('ElasticNetCV', ElasticNetCV(cv=cv_inner, n_alphas=100, random_state=random_st,fit_intercept=1)))\n",
    "estimators_ENetCV.append(('ElasticNet', search))\n",
    "\n",
    "elastic_score = regression_model(estimators_ENetCV)\n",
    "scores.append(['ElasticNet',elastic_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954a15ff-0c5f-46b3-9da7-bff1922f196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcfc689-a9ac-4823-8ffb-5d45791cd492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968f22a3-0984-4197-a5c8-8cf1399eaf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca98d9f-5589-4e61-bec1-f6da433a45b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c21341-e6f7-404b-8a7e-2f28d527a5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4576646-4d1e-45d4-a88d-294930236c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear\n",
    "\n",
    "# define the model\n",
    "\n",
    "#linear_enet = ElasticNetCV(cv=cv_inner,alphas=[0], l1_ratio=0,fit_intercept = True)\n",
    "linear_enet = ElasticNetCV(cv=cv_inner,alphas=[0], l1_ratio=0,fit_intercept = True)\n",
    "\n",
    "sfs = SFS(linear_enet, \n",
    "          k_features=len(X.columns), \n",
    "          forward=True, \n",
    "          floating=True, \n",
    "          scoring='neg_mean_squared_error',\n",
    "          cv=cv_inner)\n",
    "\n",
    "estimators_linear = []\n",
    "estimators_linear.append(('standardize', ZCA()))\n",
    "estimators_linear.append(('SFS', sfs))\n",
    "estimators_linear.append(('linear_enet', linear_enet))\n",
    "grid = dict()\n",
    "grid['alpha'] = [0]\n",
    "grid['l1_ratio'] = [0]\n",
    "search = GridSearchCV(model, grid, scoring='neg_mean_squared_error', n_jobs=1, cv=cv_inner, refit=True)\n",
    "\n",
    "linear_score = regression_model(estimators_linear)\n",
    "scores.append(['linear_enet',linear_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0f34a3-2ea8-4596-80c9-9feec99bc316",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in range(0,len(scores)):\n",
    "    print('Model: ', scores[s][0])\n",
    "    print('Accuracy: %.3f (%.3f)' % (scores[s][1].score[0][0], scores[s][1].score[0][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10e344b-9664-4243-be07-ab3ce9213b22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4357f490-8d11-4f01-939d-484ba53e1c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b7802e-911b-4813-8448-1df9921800df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb4054d-4436-4f13-abac-6280e877a5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1\n",
    "best_model = [item[0] for item in scores][np.argmin(np.abs([item[1].score[0][0] for item in scores]))]\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cbc8c4-4317-4ba2-994a-0de66048561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if(best_model=='ElasticNetCV'):\n",
    "    zca = ZCA()\n",
    "    zca.fit(X)\n",
    "    \n",
    "    #Step 2: inner-procedure is applied to the entire dataset.\n",
    "    final_model_est = Pipeline(estimators_ENetCV)\n",
    "    final_model_est.fit(X,y)\n",
    "    #final_model_est = ElasticNetCV(alphas=[final_model_est.named_steps['ElasticNetCV'].alpha_], l1_ratio=final_model_est.named_steps['ElasticNetCV'].l1_ratio,fit_intercept=True)\n",
    "    \n",
    "    #final_model_est.fit(zca.transform(X), y)\n",
    "    \n",
    "    #step 3: hyperparameters found during this final search are then used to configure a final model.\n",
    "    estimators_final = []\n",
    "    #estimators_final.append(('standardize', ZCA()))\n",
    "    estimators_final.append(('ElasticNet', ElasticNetCV(cv=cv_inner,alphas=[final_model_est.named_steps['ElasticNetCV'].alpha_], l1_ratio=final_model_est.named_steps['ElasticNetCV'].l1_ratio,fit_intercept=True)))\n",
    "    final_model = Pipeline(estimators_final)\n",
    "    \n",
    "    final_model.fit(zca.transform(X),y)    \n",
    "    \n",
    "    #step 4: final model is fit on the entire dataset.\n",
    "    plt.scatter(final_model.predict(zca.transform(X)),y)\n",
    "    plt.show()\n",
    "    print(mean_squared_error(y, final_model.predict(zca.transform(X)), squared=True))\n",
    "    \n",
    "    #Step 2: inner-procedure is applied to the entire dataset.\n",
    "    final_model_est = Pipeline(estimators_ENetCV)\n",
    "    final_model_est.fit(X,y)\n",
    "    #final_model_est = ElasticNetCV(alphas=[final_model_est.named_steps['ElasticNetCV'].alpha_], l1_ratio=final_model_est.named_steps['ElasticNetCV'].l1_ratio,fit_intercept=True)\n",
    "    \n",
    "    #final_model_est.fit(zca.transform(X), y)\n",
    "    \n",
    "    #step 3: hyperparameters found during this final search are then used to configure a final model.\n",
    "    estimators_final = []\n",
    "    #estimators_final.append(('standardize', ZCA()))\n",
    "    estimators_final.append(('ElasticNet', ElasticNetCV(cv=cv_inner,alphas=[final_model_est.named_steps['ElasticNetCV'].alpha_], l1_ratio=final_model_est.named_steps['ElasticNetCV'].l1_ratio,fit_intercept=True)))\n",
    "    final_model = Pipeline(estimators_final)\n",
    "    \n",
    "    final_model.fit(final_model_est.named_steps['standardize'].transform(X),y)    \n",
    "    \n",
    "    #step 4: final model is fit on the entire dataset.\n",
    "    plt.scatter(final_model.predict(final_model_est.named_steps['standardize'].transform(X)),y)\n",
    "    plt.show()\n",
    "    print(mean_squared_error(y, final_model.predict(final_model_est.named_steps['standardize'].transform(X)), squared=True))\n",
    "        \n",
    "elif(best_model=='linear_enet'):\n",
    "    final_model_est = Pipeline(estimators_linear)\n",
    "    \n",
    "    final_model_est.fit(X,y)\n",
    "    \n",
    "    bestSFS=X.columns[pd.Series(pd.DataFrame(final_model_est.named_steps['SFS'].subsets_).iloc[:,np.argmin(np.abs(pd.DataFrame(final_model_est.named_steps['SFS'].subsets_).loc['avg_score']))-1].feature_idx).to_list()]\n",
    "    \n",
    "    #Step 2: inner-procedure is applied to the entire dataset.\n",
    "    #step 3: hyperparameters found during this final search are then used to configure a final model.\n",
    "    #no need to derive hyper parm's\n",
    "    final_model = ElasticNetCV(cv=cv_inner,alphas=[0], l1_ratio=0,fit_intercept=True)\n",
    "    \n",
    "    zca = ZCA()\n",
    "    zca.fit(X[bestSFS])\n",
    "    \n",
    "    final_model.fit(zca.transform(X[bestSFS]), y)\n",
    "    \n",
    "    #final_model.fit(zca.transform(X),y)    \n",
    "    \n",
    "    #step 4: final model is fit on the entire dataset.\n",
    "    plt.scatter(final_model.predict(zca.transform(X[bestSFS])),y)\n",
    "    plt.show()\n",
    "    print(mean_squared_error(y, final_model.predict(zca.transform(X[bestSFS])), squared=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419990a6-c118-4dfd-89b1-e6aaf7a31e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
