{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbb1adca-d35a-4671-9667-bffad54974e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# automatic nested cross-validation for random forest on a classification dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "import itertools\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import ElasticNet\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error \n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "from random import sample\n",
    "import random\n",
    "random_st = random.sample(list(np.arange(0,10,1)),1)[0]\n",
    "print(random_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc685d3a-564a-4092-a219-9eef11441886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# ------------------------------------\n",
    "# file: zca.py\n",
    "# date: Thu May 21 15:47 2015\n",
    "# author:\n",
    "# Maarten Versteegh\n",
    "# github.com/mwv\n",
    "# maartenversteegh AT gmail DOT com\n",
    "#\n",
    "# Licensed under GPLv3\n",
    "# ------------------------------------\n",
    "\"\"\"zca: ZCA whitening with a sklearn-like interface\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.utils import check_array, as_float_array\n",
    "\n",
    "class ZCA(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, regularization=1e-6, copy=False):\n",
    "        self.regularization = regularization\n",
    "        self.copy = copy\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Compute the mean, whitening and dewhitening matrices.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like with shape [n_samples, n_features]\n",
    "            The data used to compute the mean, whitening and dewhitening\n",
    "            matrices.\n",
    "        \"\"\"\n",
    "        X = check_array(X, accept_sparse=None, copy=self.copy,\n",
    "                        ensure_2d=True)\n",
    "        X = as_float_array(X, copy=self.copy)\n",
    "        self.mean_ = X.mean(axis=0)\n",
    "        X_ = X - self.mean_\n",
    "        cov = np.dot(X_.T, X_) / (X_.shape[0]-1)\n",
    "        U, S, _ = linalg.svd(cov)\n",
    "        s = np.sqrt(S.clip(self.regularization))\n",
    "        s_inv = np.diag(1./s)\n",
    "        s = np.diag(s)\n",
    "        self.whiten_ = np.dot(np.dot(U, s_inv), U.T)\n",
    "        self.dewhiten_ = np.dot(np.dot(U, s), U.T)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, copy=None):\n",
    "        \"\"\"Perform ZCA whitening\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like with shape [n_samples, n_features]\n",
    "            The data to whiten along the features axis.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, 'mean_')\n",
    "        X = as_float_array(X, copy=self.copy)\n",
    "        return np.dot(X - self.mean_, self.whiten_.T)\n",
    "\n",
    "    def inverse_transform(self, X, copy=None):\n",
    "        \"\"\"Undo the ZCA transform and rotate back to the original\n",
    "        representation\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like with shape [n_samples, n_features]\n",
    "            The data to rotate back.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, 'mean_')\n",
    "        X = as_float_array(X, copy=self.copy)\n",
    "        return np.dot(X, self.dewhiten_) + self.mean_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53dae0be-aa5b-41a6-ac79-03045466367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    df = pd.read_csv(\"https://raw.githubusercontent.com/thistleknot/Python-Stock/master/data/raw/states.csv\").set_index('States')\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a98ab490-94f1-49b3-97f0-d4d0e3e331c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "independent = 'Poverty'\n",
    "outer_k = 10\n",
    "inner_k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f0f0f45-3357-492d-86de-7aabd366e6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "y = read_data()[[independent]]\n",
    "X = read_data()[(read_data().columns).difference([independent]).values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89602861-d308-493a-81d0-56f81882fd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: -2.479 (2.447)\n"
     ]
    }
   ],
   "source": [
    "#elastic\n",
    "\n",
    "# configure the cross-validation procedure\n",
    "cv_inner = KFold(n_splits=inner_k, shuffle=True, random_state=random_st)\n",
    "# define the model\n",
    "\n",
    "estimators_ENetCV = []\n",
    "estimators_ENetCV.append(('standardize', ZCA()))\n",
    "estimators_ENetCV.append(('ElasticNetCV', ElasticNetCV(cv=cv_inner, random_state=random_st,fit_intercept=1)))\n",
    "\n",
    "# define search\n",
    "search_en = Pipeline(estimators_ENetCV)\n",
    "\n",
    "# configure the cross-validation procedure\n",
    "cv_outer = KFold(n_splits=outer_k, shuffle=True, random_state=random_st)\n",
    "\n",
    "# execute the nested cross-validation\n",
    "scores = cross_val_score(search_en, X, y, scoring='neg_mean_squared_error', cv=cv_outer, n_jobs=-1)\n",
    "# report performance\n",
    "\n",
    "elastic_score = 'Accuracy: %.3f (%.3f)' % (mean(scores), std(scores))\n",
    "print(elastic_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ee9679-f51e-4064-9d73-d0a9a6d84b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4576646-4d1e-45d4-a88d-294930236c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: -2.472 (2.399)\n"
     ]
    }
   ],
   "source": [
    "#linear\n",
    "\n",
    "# configure the cross-validation procedure\n",
    "cv_inner = KFold(n_splits=inner_k, shuffle=True, random_state=random_st)\n",
    "# define the model\n",
    "\n",
    "estimators_linear = []\n",
    "estimators_linear.append(('standardize', ZCA()))\n",
    "estimators_linear.append(('Linear', ElasticNetCV(cv=cv_inner,alphas=[0], l1_ratio=0,fit_intercept = True)))\n",
    "\n",
    "# define search space\n",
    "# define search\n",
    "search = Pipeline(estimators_linear)\n",
    "# configure the cross-validation procedure\n",
    "cv_outer = KFold(n_splits=outer_k, shuffle=True, random_state=random_st)\n",
    "# execute the nested cross-validation\n",
    "scores = cross_val_score(search, X, y, scoring='neg_mean_squared_error', cv=cv_outer, n_jobs=-1)\n",
    "# report performance\n",
    "Linear_score = 'Accuracy: %.3f (%.3f)' % (mean(scores), std(scores))\n",
    "print(Linear_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0f34a3-2ea8-4596-80c9-9feec99bc316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
