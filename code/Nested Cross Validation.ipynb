{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92de849c-fc6a-4fb9-ac6f-186d17b2b923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatic nested cross-validation of regression of 'Linear Regression using Step Forward Feature Selection' contrasted with 'Elastic Net' using pipelines as well as ZCA whitening to scale variables..\n",
    "\n",
    "#https://machinelearningmastery.com/nested-cross-validation-for-machine-learning-with-python/\n",
    "#https://machinelearningmastery.com/elastic-net-regression-in-python/\n",
    "#https://github.com/rasbt/mlxtend/issues/41\n",
    "#https://github.com/rasbt/mlxtend/issues/69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbb1adca-d35a-4671-9667-bffad54974e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "from numpy import arange\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from random import sample\n",
    "\n",
    "import random\n",
    "\n",
    "import re\n",
    "\n",
    "#from sklearn.datasets import make_classification\n",
    "from sklearn import linear_model\n",
    "from sklearn.datasets import make_regression\n",
    "#from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc685d3a-564a-4092-a219-9eef11441886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# ------------------------------------\n",
    "# file: zca.py\n",
    "# date: Thu May 21 15:47 2015\n",
    "# author:\n",
    "# Maarten Versteegh\n",
    "# github.com/mwv\n",
    "# maartenversteegh AT gmail DOT com\n",
    "#\n",
    "# Licensed under GPLv3\n",
    "# ------------------------------------\n",
    "\"\"\"zca: ZCA whitening with a sklearn-like interface\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.utils import check_array, as_float_array\n",
    "\n",
    "class ZCA(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, regularization=1e-6, copy=False):\n",
    "        self.regularization = regularization\n",
    "        self.copy = copy\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Compute the mean, whitening and dewhitening matrices.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like with shape [n_samples, n_features]\n",
    "            The data used to compute the mean, whitening and dewhitening\n",
    "            matrices.\n",
    "        \"\"\"\n",
    "        X = check_array(X, accept_sparse=None, copy=self.copy,\n",
    "                        ensure_2d=True)\n",
    "        X = as_float_array(X, copy=self.copy)\n",
    "        self.mean_ = X.mean(axis=0)\n",
    "        X_ = X - self.mean_\n",
    "        cov = np.dot(X_.T, X_) / (X_.shape[0]-1)\n",
    "        U, S, _ = linalg.svd(cov)\n",
    "        s = np.sqrt(S.clip(self.regularization))\n",
    "        s_inv = np.diag(1./s)\n",
    "        s = np.diag(s)\n",
    "        self.whiten_ = np.dot(np.dot(U, s_inv), U.T)\n",
    "        self.dewhiten_ = np.dot(np.dot(U, s), U.T)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, copy=None):\n",
    "        \"\"\"Perform ZCA whitening\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like with shape [n_samples, n_features]\n",
    "            The data to whiten along the features axis.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, 'mean_')\n",
    "        X = as_float_array(X, copy=self.copy)\n",
    "        return np.dot(X - self.mean_, self.whiten_.T)\n",
    "\n",
    "    def inverse_transform(self, X, copy=None):\n",
    "        \"\"\"Undo the ZCA transform and rotate back to the original\n",
    "        representation\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like with shape [n_samples, n_features]\n",
    "            The data to rotate back.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, 'mean_')\n",
    "        X = as_float_array(X, copy=self.copy)\n",
    "        return np.dot(X, self.dewhiten_) + self.mean_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53dae0be-aa5b-41a6-ac79-03045466367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    df = pd.read_csv(\"https://raw.githubusercontent.com/thistleknot/Python-Stock/master/data/raw/states.csv\").set_index('States')\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a98ab490-94f1-49b3-97f0-d4d0e3e331c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "independent = 'Poverty'\n",
    "outer_k = 10\n",
    "inner_k = 10\n",
    "random_st = random.sample(list(np.arange(0,10,1)),1)[0]\n",
    "print(random_st)\n",
    "\n",
    "# configure the cross-validation procedure\n",
    "cv_inner = KFold(n_splits=inner_k, shuffle=True, random_state=random_st)\n",
    "cv_outer = KFold(n_splits=outer_k, shuffle=True, random_state=random_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f0f0f45-3357-492d-86de-7aabd366e6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "y = read_data()[[independent]]\n",
    "X = read_data()[(read_data().columns).difference([independent]).values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89602861-d308-493a-81d0-56f81882fd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: -2.492 (2.695)\n"
     ]
    }
   ],
   "source": [
    "#elastic\n",
    "\n",
    "# define the model\n",
    "\n",
    "estimators_ENetCV = []\n",
    "estimators_ENetCV.append(('standardize', ZCA()))\n",
    "estimators_ENetCV.append(('ElasticNetCV', ElasticNetCV(cv=cv_inner, random_state=random_st,fit_intercept=1)))\n",
    "\n",
    "# define search\n",
    "search_en = Pipeline(estimators_ENetCV)\n",
    "\n",
    "# execute the nested cross-validation\n",
    "elastic_scores = cross_val_score(search_en, X, y, scoring='neg_mean_squared_error', cv=cv_outer, n_jobs=-1)\n",
    "# report performance\n",
    "\n",
    "elastic_score = [(mean(elastic_scores), std(elastic_scores))]\n",
    "print('Accuracy: %.3f (%.3f)' % (elastic_score[0][0], elastic_score[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcf64b7-8c38-40e9-8322-5bda8a16c74c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4576646-4d1e-45d4-a88d-294930236c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: -2.597 (2.964)\n"
     ]
    }
   ],
   "source": [
    "#linear\n",
    "\n",
    "# define the model\n",
    "\n",
    "linear_enet = ElasticNetCV(cv=cv_inner,alphas=[0], l1_ratio=0,fit_intercept = True)\n",
    "\n",
    "sfs = SFS(linear_enet, \n",
    "          k_features=len(X.columns), \n",
    "          forward=True, \n",
    "          floating=True, \n",
    "          scoring='neg_mean_squared_error',\n",
    "          cv=cv_inner)\n",
    "\n",
    "estimators_linear = []\n",
    "estimators_linear.append(('standardize', ZCA()))\n",
    "estimators_linear.append(('SFS', sfs))\n",
    "estimators_linear.append(('linear_enet', linear_enet))\n",
    "\n",
    "#model_en = Pipeline(estimators)\n",
    "\n",
    "# define search space\n",
    "\n",
    "search_linear = Pipeline(estimators_linear)\n",
    "# configure the cross-validation procedure\n",
    "\n",
    "# execute the nested cross-validation\n",
    "linear_scores = cross_val_score(search_linear, X, y, scoring='neg_mean_squared_error', cv=cv_outer, n_jobs=-1)\n",
    "# report performance\n",
    "Linear_score = [(mean(linear_scores), std(linear_scores))]\n",
    "print('Accuracy: %.3f (%.3f)' % (Linear_score[0][0], Linear_score[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0f34a3-2ea8-4596-80c9-9feec99bc316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
