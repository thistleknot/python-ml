{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eeb588-d5bc-4fc1-bf41-6d52ebbefcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import FloatSlider\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import matplotlib\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing as skp\n",
    "import pingouin as pg\n",
    "from OLS_LR_DiagnosticPlots.ModelDiagnostics import Plot\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import scipy\n",
    "from sklearn.utils import check_array, as_float_array\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn import datasets\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from IPython.display import display, clear_output\n",
    "from scipy.stats import moment\n",
    "import holoviews as hv\n",
    "from holoviews import dim, opts\n",
    "import matplotlib.cm as cm\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dbc217-d142-4ee3-82fa-bf861697ac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from k_means_constrained import KMeansConstrained\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import rpy2\n",
    "import rpy2.robjects as ro\n",
    "import os\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "from rpy2.robjects.packages import importr\n",
    "import time\n",
    "import random\n",
    "import time\n",
    "from numpy.random import seed\n",
    "from scipy.stats import f\n",
    "from PIL import Image\n",
    "#hv.extension('matplotlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90d0183-5feb-461d-b3f3-497e72fead43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2\n",
    "import rpy2.robjects as ro\n",
    "import os\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "from rpy2.robjects.packages import importr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddea09b8-e499-4185-b9a5-c6fa4d530113",
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = os.getcwd()\n",
    "\n",
    "if (os.defpath==\".;C:\\\\bin\"):\n",
    "    os.environ['R_HOME'] = 'C:/Users/User/Documents/R/R-4.1.2'\n",
    "    os.environ['R_LIBS'] = 'C:/Users/User/Documents/R/R-4.1.2/library'\n",
    "    from OLS_LR_DiagnosticPlots.ModelDiagnostics import Plot\n",
    "else:\n",
    "    os.environ['R_HOME'] = '/mnt/distvol/R/4.0.5/lib64/R/'\n",
    "\n",
    "pandas2ri.activate()\n",
    "\n",
    "base = importr('base')\n",
    "grdevices = importr('grDevices')\n",
    "print(base._libPaths())\n",
    "\n",
    "#urbnmapr = importr('urbnmapr')\n",
    "dplyr = importr('dplyr')\n",
    "tidyverse = importr('tidyverse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccd960d-bca6-46bd-8c2a-79a389ae0036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(Y_actual,Y_Predicted):\n",
    "    mape = np.mean(np.abs((Y_actual - Y_Predicted)/Y_actual))*100\n",
    "    return mape\n",
    "\n",
    "def f_test(x, y, alt=\"two_sided\"):\n",
    "    \"\"\"\n",
    "    Calculates the F-test.\n",
    "    :param x: The first group of data\n",
    "    :param y: The second group of data\n",
    "    :param alt: The alternative hypothesis, one of \"two_sided\" (default), \"greater\" or \"less\"\n",
    "    :return: a tuple with the F statistic value and the p-value.\n",
    "    \"\"\"\n",
    "    df1 = len(x) - 1\n",
    "    df2 = len(y) - 1\n",
    "    f = x.var() / y.var()\n",
    "    if alt == \"greater\":\n",
    "        p = 1.0 - st.f.cdf(f, df1, df2)\n",
    "    elif alt == \"less\":\n",
    "        p = st.f.cdf(f, df1, df2)\n",
    "    else:\n",
    "        # two-sided by default\n",
    "        # Crawley, the R book, p.355\n",
    "        p = 2.0*(1.0 - st.f.cdf(f, df1, df2))\n",
    "    return f, p\n",
    "\n",
    "def whiten(X, method='zca'):\n",
    "\t\t\"\"\"\n",
    "\t\tWhitens the input matrix X using specified whitening method.\n",
    "\t\tInputs:\n",
    "\t\t\tX:      Input data matrix with data examples along the first dimension\n",
    "\t\t\tmethod: Whitening method. Must be one of 'zca', 'zca_cor', 'pca',\n",
    "\t\t\t\t\t'pca_cor', or 'cholesky'.\n",
    "\t\t\"\"\"\n",
    "\t\tX = X.reshape((-1, np.prod(X.shape[1:])))\n",
    "\t\tX_centered = X - np.mean(X, axis=0)\n",
    "\t\tSigma = np.dot(X_centered.T, X_centered) / X_centered.shape[0]\n",
    "\t\tW = None\n",
    "\t\tif method in ['zca', 'pca', 'cholesky']:\n",
    "\t\t\tU, Lambda, _ = np.linalg.svd(Sigma)\n",
    "\t\t\tif method == 'zca':\n",
    "\t\t\t\tW = np.dot(U, np.dot(np.diag(1.0 / np.sqrt(Lambda + 1e-5)), U.T))\n",
    "\t\t\telif method =='pca':\n",
    "\t\t\t\tW = np.dot(np.diag(1.0 / np.sqrt(Lambda + 1e-5)), U.T)\n",
    "\t\t\telif method == 'cholesky':\n",
    "\t\t\t\tW = np.linalg.cholesky(np.dot(U, np.dot(np.diag(1.0 / (Lambda + 1e-5)), U.T))).T\n",
    "\t\telif method in ['zca_cor', 'pca_cor']:\n",
    "\t\t\tV_sqrt = np.diag(np.std(X, axis=0))\n",
    "\t\t\tP = np.dot(np.dot(np.linalg.inv(V_sqrt), Sigma), np.linalg.inv(V_sqrt))\n",
    "\t\t\tG, Theta, _ = np.linalg.svd(P)\n",
    "\t\t\tif method == 'zca_cor':\n",
    "\t\t\t\tW = np.dot(np.dot(G, np.dot(np.diag(1.0 / np.sqrt(Theta + 1e-5)), G.T)), np.linalg.inv(V_sqrt))\n",
    "\t\t\telif method == 'pca_cor':\n",
    "\t\t\t\tW = np.dot(np.dot(np.diag(1.0/np.sqrt(Theta + 1e-5)), G.T), np.linalg.inv(V_sqrt))\n",
    "\t\telse:\n",
    "\t\t\traise Exception('Whitening method not found.')\n",
    "\t\treturn np.dot(X_centered, W.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcdf987-3ad3-44dc-a884-6683e809bcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    df = pd.read_csv(\"https://raw.githubusercontent.com/thistleknot/Python-Stock/master/data/raw/states.csv\").set_index('States')\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eda03a-a532-408f-ab6e-89b8e0610654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11a238d-2087-483c-bf26-3768af498b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002f2624-563c-43f4-80b3-18bf9a11c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laferriere Transform\n",
    "print(\"scatterplot of transformed values w Z scores\")\n",
    "\n",
    "def laferriere_transform (data, method):\n",
    "    \n",
    "    dataFrame = pd.DataFrame()\n",
    "\n",
    "    if(method=='mean'):\n",
    "        df_scaled = pd.DataFrame(StandardScaler().fit_transform(data),columns=data.columns).set_index(data.index)\n",
    "        for c in data.columns:\n",
    "            lower_index_ = df_scaled[[c]].sort_values(kind=\"quicksort\", by=c,ascending=False)[df_scaled[[c]].sort_values(kind=\"quicksort\", by=c,ascending=False)<0].cumsum().dropna()\n",
    "            lower_index_ = lower_index_/lower_index_.min()\n",
    "            lower_index_ = abs(((lower_index_-.5)-.5))/2\n",
    "            upper_index_ = df_scaled[[c]].sort_values(kind=\"quicksort\", by=c,ascending=True)[df_scaled[[c]].sort_values(kind=\"quicksort\", by=c,ascending=True)>=0].cumsum().dropna()            \n",
    "            upper_index_ = upper_index_/upper_index_.max()/2+.5            \n",
    "            together_index = pd.concat([lower_index_,upper_index_],axis=0)            \n",
    "            together_index.columns = [c]\n",
    "            together_index = together_index.sort_values(kind=\"quicksort\", by=c,ascending=True)\n",
    "            dataFrame = pd.concat([dataFrame,together_index],axis=1)            \n",
    "                    \n",
    "            plt.scatter(pd.concat([together_index,df_scaled[[c]]],axis=1).iloc[:,0],pd.concat([together_index,df_scaled[[c]]],axis=1).iloc[:,1])\n",
    "            \n",
    "           \n",
    "    elif(method=='median'):\n",
    "        df_scaled = pd.DataFrame((data-np.median(data,axis=0))/stats.median_abs_deviation(data),columns=data.columns).set_index(data.index)\n",
    "        for c in data.columns:\n",
    "            lower_index_ = df_scaled[[c]].sort_values(kind=\"quicksort\", by=c,ascending=False)[df_scaled[[c]].sort_values(kind=\"quicksort\", by=c,ascending=False)<0].cumsum().dropna()\n",
    "            lower_index_ = lower_index_/lower_index_.min()\n",
    "            lower_index_ = abs(((lower_index_-.5)-.5))/2\n",
    "            upper_index_ = df_scaled[[c]].sort_values(kind=\"quicksort\", by=c,ascending=True)[df_scaled[[c]].sort_values(kind=\"quicksort\", by=c,ascending=True)>=0].cumsum().dropna()\n",
    "            upper_index_ = upper_index_/upper_index_.max()/2+.5\n",
    "            together_index = pd.concat([lower_index_,upper_index_],axis=0)\n",
    "            together_index.columns = [c]\n",
    "            together_index = together_index.sort_values(kind=\"quicksort\", by=c,ascending=True)\n",
    "            dataFrame = pd.concat([dataFrame,together_index],axis=1)\n",
    "            \n",
    "            plt.scatter(pd.concat([together_index,df_scaled[[c]]],axis=1).iloc[:,0],pd.concat([together_index,df_scaled[[c]]],axis=1).iloc[:,1])\n",
    "            #plt.show()\n",
    "\n",
    "    plt.show()\n",
    "    return(dataFrame)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2540f71-27e5-446e-9dc7-7ff1da305f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247aefe8-0eab-4f4c-8455-e3741e5cf7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method = 'mean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e239070a-fb1a-4f1b-942f-4c53cdf2d935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aab8d42-b261-490d-8360-459bba8af914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1881efa0-0dd8-407f-9124-cd01acd31036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae4d65f-9d7e-40f6-b5cb-1f6bdb74f0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befa2093-39bc-47db-8b73-fb10bf3e7ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77299f54-3a54-4d58-9aa5-f6cdc525fd97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8effa93c-19c1-4ad7-9ea0-c62617da1028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e9095a-0a07-4c8d-80d6-6fcfe837de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_state_to_abbrev = {\n",
    "    \"Alabama\": \"AL\",\n",
    "    \"Alaska\": \"AK\",\n",
    "    \"Arizona\": \"AZ\",\n",
    "    \"Arkansas\": \"AR\",\n",
    "    \"California\": \"CA\",\n",
    "    \"Colorado\": \"CO\",\n",
    "    \"Connecticut\": \"CT\",\n",
    "    \"Delaware\": \"DE\",\n",
    "    \"Florida\": \"FL\",\n",
    "    \"Georgia\": \"GA\",\n",
    "    \"Hawaii\": \"HI\",\n",
    "    \"Idaho\": \"ID\",\n",
    "    \"Illinois\": \"IL\",\n",
    "    \"Indiana\": \"IN\",\n",
    "    \"Iowa\": \"IA\",\n",
    "    \"Kansas\": \"KS\",\n",
    "    \"Kentucky\": \"KY\",\n",
    "    \"Louisiana\": \"LA\",\n",
    "    \"Maine\": \"ME\",\n",
    "    \"Maryland\": \"MD\",\n",
    "    \"Massachusetts\": \"MA\",\n",
    "    \"Michigan\": \"MI\",\n",
    "    \"Minnesota\": \"MN\",\n",
    "    \"Mississippi\": \"MS\",\n",
    "    \"Missouri\": \"MO\",\n",
    "    \"Montana\": \"MT\",\n",
    "    \"Nebraska\": \"NE\",\n",
    "    \"Nevada\": \"NV\",\n",
    "    \"New Hampshire\": \"NH\",\n",
    "    \"New Jersey\": \"NJ\",\n",
    "    \"New Mexico\": \"NM\",\n",
    "    \"New York\": \"NY\",\n",
    "    \"North Carolina\": \"NC\",\n",
    "    \"North Dakota\": \"ND\",\n",
    "    \"Ohio\": \"OH\",\n",
    "    \"Oklahoma\": \"OK\",\n",
    "    \"Oregon\": \"OR\",\n",
    "    \"Pennsylvania\": \"PA\",\n",
    "    \"Rhode Island\": \"RI\",\n",
    "    \"South Carolina\": \"SC\",\n",
    "    \"South Dakota\": \"SD\",\n",
    "    \"Tennessee\": \"TN\",\n",
    "    \"Texas\": \"TX\",\n",
    "    \"Utah\": \"UT\",\n",
    "    \"Vermont\": \"VT\",\n",
    "    \"Virginia\": \"VA\",\n",
    "    \"Washington\": \"WA\",\n",
    "    \"West Virginia\": \"WV\",\n",
    "    \"Wisconsin\": \"WI\",\n",
    "    \"Wyoming\": \"WY\",\n",
    "    \"District of Columbia\": \"DC\",\n",
    "    \"American Samoa\": \"AS\",\n",
    "    \"Guam\": \"GU\",\n",
    "    \"Northern Mariana Islands\": \"MP\",\n",
    "    \"Puerto Rico\": \"PR\",\n",
    "    \"United States Minor Outlying Islands\": \"UM\",\n",
    "    \"U.S. Virgin Islands\": \"VI\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22b920a-7cd6-4517-be06-3d0742ed3cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro.r('''\n",
    "\n",
    "f <- function(df) {\n",
    "library(urbnmapr)\n",
    "library(viridis)\n",
    "library(hrbrthemes)\n",
    "library(dplyr)\n",
    "#print(df)\n",
    "spatial_data <- left_join(get_urbn_map(map = \"states\", sf = TRUE),\n",
    "                          statedata,\n",
    "                          by = \"state_name\")\n",
    "\n",
    "spatial_data <- spatial_data[spatial_data$state_name %in% df$States,] %>% left_join(df, by = c('state_name' = 'States'))\n",
    "spatial_data$cluster <- factor(spatial_data$cluster)\n",
    "\n",
    "print(paste(\"C:\\\\\\\\Users\\\\\\\\User\\\\\\\\Documents\\\\\\\\wiki\\\\\\\\wiki\\\\\\\\dev\\\\\\\\R\\\\\\\\\",\"clusterMap\",sep = \"\",\".png\"),width = 1200, height = 800, units = \"px\", pointsize = 12, quality = 90)\n",
    "jpeg(paste(\"C:\\\\\\\\Users\\\\\\\\User\\\\\\\\Documents\\\\\\\\wiki\\\\\\\\wiki\\\\\\\\dev\\\\\\\\R\\\\\\\\\",\"clusterMap\",sep = \"\",\".png\"),width = 1200, height = 800, units = \"px\", pointsize = 12, quality = 90)\n",
    "\n",
    "p <- ggplot() +\n",
    "  geom_sf(spatial_data,\n",
    "          mapping = aes(fill = cluster),\n",
    "          color = \"#ffffff\", size = 0.25) + scale_fill_discrete() +\n",
    "  geom_sf_text(data = get_urbn_labels(map = \"states\", sf = TRUE), \n",
    "               aes(label = state_abbv), \n",
    "               size = 3)\n",
    "  labs(fill = \"cluster\")\n",
    "\n",
    "plot(p)\n",
    "dev.off() \n",
    "\n",
    "}\n",
    "\n",
    "''')\n",
    "\n",
    "r_f = ro.globalenv['f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf0e0f1-b3a7-4032-b0be-3235751552c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db739108-0491-4560-bb80-f4456c568744",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[['Poverty', 'White', 'Traf Deaths', 'University', 'Unemployed', 'Income', 'Population']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fc19ba-db4b-49b9-ad93-145c65f1db39",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "output_figure = widgets.Output()\n",
    " \n",
    "# Create the default figure\n",
    "fig = []  # Storing the figure in a singular list is a bit of a \n",
    "          # hack. We need it to properly mutate the current\n",
    "          # figure in our callbacks.\n",
    "#p = create_figure(\n",
    "#    iris['feature_names'][0],\n",
    "#    iris['feature_names'][1],\n",
    "#    data)\n",
    "#fig.append(p)\n",
    "with output_figure:\n",
    "    interact(derive_xnames,y=y)\n",
    "    #interact(return_model_vars,x=x_,y=y,autoremove=autoremove)\n",
    "    #show(fig)\n",
    "    \n",
    "app_layout = widgets.Layout(display='flex',\n",
    "                flex_flow='row nowrap',\n",
    "                align_items='center',\n",
    "                border='none',\n",
    "                width='100%',\n",
    "                margin='5px 5px 5px 5px')\n",
    " \n",
    "# The final app is just a box\n",
    "app=widgets.Box([y, output_figure], layout=app_layout)\n",
    " \n",
    "# Display the app\n",
    "display(app)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ab5b9b-952d-4811-8621-658febe02bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_model_vars(x,y,autoremove):\n",
    "    #print(x)\n",
    "    names = [y,*x]\n",
    "    print(names)\n",
    "    \n",
    "    shap.initjs()\n",
    "    \n",
    "    data = df[names].sort_values(kind=\"quicksort\", by=names[0], ascending=True,key=abs).copy()\n",
    "    \n",
    "    loop=True\n",
    "    \n",
    "    removes = []\n",
    "    if(autoremove):\n",
    "        while(loop==True):\n",
    "\n",
    "            x_names = data.columns[~data.columns.isin([item for item in [y,*removes]])]\n",
    "\n",
    "            #x_scores = data[[y,*x_names]].pcorr()[[y]]\n",
    "\n",
    "            x_scores = pd.concat([data[y],pd.DataFrame(whiten(np.array(data[x_names])),columns=x_names).set_index(data.index)],axis=1).pcorr()[[y]]\n",
    "\n",
    "            #print(x_scores.loc[~x_scores.index.isin([y])])\n",
    "\n",
    "            print(x_names)\n",
    "\n",
    "            index_set = data.index\n",
    "\n",
    "            test_results = x_scores\n",
    "\n",
    "            n = len(index_set)\n",
    "            df_ = n - 2\n",
    "\n",
    "            t=abs(test_results)*np.sqrt(df_)/np.sqrt(1-abs(test_results)**2)\n",
    "\n",
    "            test_results_least = t.iloc[[np.argmin(abs(t))]].index[0]\n",
    "\n",
    "            t_score_least = t.iloc[[np.argmin(abs(t))]]\n",
    "\n",
    "            crit_t = scipy.stats.t.ppf(1 - .05 / 2, df_)\n",
    "\n",
    "            if(np.isnan(t_score_least.values[0][0])):\n",
    "                remove = test_results_least\n",
    "                removes.append(remove)\n",
    "\n",
    "            if((t.loc[test_results_least]<crit_t)[0]):\n",
    "                remove = test_results_least\n",
    "                #print(remove,t_score_least.values[0][0])\n",
    "                removes.append(remove)\n",
    "\n",
    "            if((t.loc[test_results_least]>crit_t)[0]):\n",
    "                loop=False\n",
    "\n",
    "            if(len(x_names)==1):\n",
    "                loop=False\n",
    "    else:\n",
    "        x_names = data.columns[~data.columns.isin([item for item in [y,*removes]])]\n",
    "\n",
    "    return([y,*x_names])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e06d30b-197a-441c-99a1-fc49266c81ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9117a824-9b85-4985-b9b3-7fee01ffde9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6592157f-f9ca-4334-aba5-9ce7f524f4eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e3d5233-8a1e-4b9c-a46d-e19fed2780f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a09be938339145ef88c0c4cafa9e8f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Select(description='y', options=('Poverty', 'Infant Mort', 'White', 'Crime', 'Doctors', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def return_model_subset(x,y,autoremove,center=center):    \n",
    "    \n",
    "    df=read_data()\n",
    "    \n",
    "    if(center):\n",
    "        method='mean'\n",
    "    else:\n",
    "        method='median'\n",
    "    \n",
    "    #print(x)\n",
    "    names = list([y,*x])\n",
    "    #display(names)\n",
    "    display(\"transformed data\")\n",
    "    \n",
    "    #print(df)\n",
    "    scaled = laferriere_transform(df[names],method)    \n",
    "    \n",
    "    #df = sm.add_constant(scaled)[[*scaled.columns,'const']]\n",
    "    #names.append('const')\n",
    "    white = pd.DataFrame(whiten(np.array(scaled)),columns=scaled.columns)\n",
    "    white.index = scaled.index\n",
    "\n",
    "    sortValue = y\n",
    "    '''\n",
    "    sortValue = widgets.Select(\n",
    "        options=white.columns,\n",
    "        value=white.columns[0],\n",
    "        # rows=10,\n",
    "        description='sort',\n",
    "        disabled=False\n",
    "        )\n",
    "    '''\n",
    "\n",
    "    def print_df_sort(sortValue):\n",
    "        #print(data)\n",
    "        sorted = white.sort_values(kind=\"quicksort\", by=sortValue, ascending=True)\n",
    "        plt.plot(sorted[sortValue])\n",
    "        plt.xticks(rotation = 45, size = 9)\n",
    "        plt.show()\n",
    "        sorted_ = pd.concat([sorted[sortValue],sorted[sorted.columns[~sorted.columns.isin([sortValue])]]],axis=1)\n",
    "        display(sorted_.style.background_gradient(cmap ='RdYlGn',axis=0))\n",
    "\n",
    "    print(\"pipeline: scaled, ZCA whitened values\")\n",
    "    interact(print_df_sort, sortValue=sortValue);  \n",
    "\n",
    "    yesNo = widgets.Checkbox(\n",
    "        value=False,\n",
    "        description='Plot each column w ZCA',\n",
    "        disabled=False,\n",
    "        indent=False\n",
    "        )\n",
    "\n",
    "    def plot_ZCA(yesNo):\n",
    "\n",
    "        if(yesNo):\n",
    "\n",
    "            print(\"whitened pcorr of transform\")\n",
    "            display(pd.DataFrame(whiten(np.array(scaled)),columns=scaled.columns).pcorr())\n",
    "            for d in scaled.columns:\n",
    "                #print(d)\n",
    "                #scaled\n",
    "                values = scaled.sort_values(kind=\"quicksort\", by= d, ascending=True)\n",
    "\n",
    "                plt.plot(pd.DataFrame((np.array(values)),columns=scaled.columns)[d])\n",
    "                #zca\n",
    "                plt.plot(pd.DataFrame(whiten(np.array(values)),columns=scaled.columns)[d])\n",
    "                plt.xticks(rotation = 45, size = 9)\n",
    "                plt.show()\n",
    "\n",
    "    print(\"plot ZCA\")\n",
    "    interact(plot_ZCA, yesNo=yesNo) \n",
    "    \n",
    "    sorted_ = scaled.sort_values(kind=\"quicksort\", by=y, ascending=True)\n",
    "    plt.plot(sorted_[y])\n",
    "    plt.xticks(rotation = 45, size = 9)\n",
    "    plt.show()\n",
    "    sorted_ = pd.concat([sorted_[y],sorted_[sorted_.columns[~sorted_.columns.isin([y])]]],axis=1)\n",
    "    \n",
    "    print(\"non linear transformed, no zca\")\n",
    "    display(sorted_.style.background_gradient(cmap ='RdYlGn',axis=0))    \n",
    "    \n",
    "    shap.initjs()\n",
    "    \n",
    "    data = scaled.sort_values(kind=\"quicksort\", by=y, ascending=True,key=abs).copy()\n",
    "    \n",
    "    loop=True\n",
    "    #print(data[y])\n",
    "    removes = []\n",
    "    if(autoremove):\n",
    "        while(loop==True):\n",
    "\n",
    "            x_names = data.columns[~data.columns.isin([item for item in [y,*removes]])]\n",
    "\n",
    "            #x_scores = data[[y,*x_names]].pcorr()[[y]]\n",
    "\n",
    "            x_scores = pd.concat([data[y],pd.DataFrame(whiten(np.array(data[x_names])),columns=x_names).set_index(data.index)],axis=1).pcorr()[[y]]\n",
    "\n",
    "            #print(x_scores.loc[~x_scores.index.isin([y])])\n",
    "\n",
    "            print(x_names)\n",
    "\n",
    "            index_set = data.index\n",
    "\n",
    "            test_results = x_scores\n",
    "\n",
    "            n = len(index_set)\n",
    "            df_ = n - 2\n",
    "\n",
    "            t=abs(test_results)*np.sqrt(df_)/np.sqrt(1-abs(test_results)**2)\n",
    "\n",
    "            test_results_least = t.iloc[[np.argmin(abs(t))]].index[0]\n",
    "\n",
    "            t_score_least = t.iloc[[np.argmin(abs(t))]]\n",
    "\n",
    "            crit_t = scipy.stats.t.ppf(1 - .05 / 2, df_)\n",
    "\n",
    "            if(np.isnan(t_score_least.values[0][0])):\n",
    "                remove = test_results_least\n",
    "                removes.append(remove)\n",
    "\n",
    "            if((t.loc[test_results_least]<crit_t)[0]):\n",
    "                remove = test_results_least\n",
    "                #print(remove,t_score_least.values[0][0])\n",
    "                removes.append(remove)\n",
    "\n",
    "            if((t.loc[test_results_least]>crit_t)[0]):\n",
    "                loop=False\n",
    "\n",
    "            if(len(x_names)==1):\n",
    "                loop=False\n",
    "    else:\n",
    "        x_names = data.columns[~data.columns.isin([item for item in [y,*removes]])]\n",
    "\n",
    "    print(x_names)\n",
    "    \n",
    "    #X = data.iloc[:,1:]\n",
    "\n",
    "    #print(data)\n",
    "    #np.concatenate(x_names,'const')\n",
    "    X = data[x_names]\n",
    "   \n",
    "    X_ = pd.DataFrame(whiten(np.array(X)),columns=X.columns).set_index(X.index)\n",
    "    X_.index = X.index\n",
    "    X_.columns = X.columns\n",
    "    X = X_\n",
    "    #print(X)\n",
    "    #Y = scale(data.iloc[:,0], scale=True)\n",
    "    #print(data.iloc[:,0].sort_values())\n",
    "    #Y = pd.DataFrame(skp.scale(data.iloc[:,0], with_mean=True, with_std=True))\n",
    "    #Y = data[[y]]    \n",
    "    \n",
    "    Y = pd.DataFrame(skp.scale(np.array(data[[y]]), with_mean=True, with_std=True))\n",
    "    #print(Y)\n",
    "    #Y = pd.DataFrame(data.iloc[:,0])\n",
    "    Y.columns = [y]\n",
    "    Y.index = data.iloc[:,0].index\n",
    "    \n",
    "    #Y.sort_values(by=y,ascending=False,inplace=True)\n",
    "    #X = X.loc[Y.index]\n",
    "    \n",
    "    model = sklearn.linear_model.LinearRegression()\n",
    "    \n",
    "    #print(pd.concat([Y,X],axis=1))\n",
    "    print(X.columns)\n",
    "    model.fit(X, Y)\n",
    "    model_ = sm.OLS(Y,X)\n",
    "    results = model_.fit()\n",
    "    #shap\n",
    "    background = np.array(X)\n",
    "    e = shap.LinearExplainer(model, X)\n",
    "    \n",
    "    shap_values = e.shap_values(np.array(X))\n",
    "    shap.summary_plot(shap_values, -np.array(X))\n",
    "    explainer = shap.Explainer(model, X)\n",
    "    shap.plots.heatmap(explainer(X))\n",
    "    \n",
    "    predict = results.predict(X.loc[Y.index])\n",
    "        \n",
    "    Y = Y.sort_values(by=y, ascending=True)\n",
    "    predict = predict.loc[Y.index]\n",
    "    \n",
    "    #print(Y)\n",
    "    \n",
    "    #print(Y)\n",
    "    #print(data.iloc[:,0])\n",
    "    #print(np.array(Y)*np.std(data.iloc[:,0])+np.mean(data.iloc[:,0]))\n",
    "    #print(np.array(predict)*np.std(data.iloc[:,0])+np.mean(data.iloc[:,0]))\n",
    "    #print(predict)\n",
    "    set_ = pd.concat([Y,predict],axis=1)\n",
    "    #print(set_)\n",
    "    set_.columns = ['raw','predict']\n",
    "    #plt.plot(np.array(Y))\n",
    "    #plt.plot(np.array(predict))\n",
    "    plt.hist(set_['raw']-set_['predict'])\n",
    "    plt.show()\n",
    "    \n",
    "    #diffed =  pd.DataFrame((np.array(Y)-np.array(predict)))\n",
    "    #plt.hist(np.array(diffed))\n",
    "    #plt.hist(np.histogram((np.array(Y)-np.array(predict))))\n",
    "    #plt.show()\n",
    "    '''\n",
    "    if(method=='mean'):\n",
    "        plt.plot(np.array(Y)*np.std(data.iloc[:,0])+np.mean(data.iloc[:,0]))\n",
    "        plt.plot(np.array(predict)*np.std(data.iloc[:,0])+np.mean(data.iloc[:,0]))\n",
    "    elif(method=='median'):\n",
    "        plt.plot(np.array(Y)*stats.median_abs_deviation(data.iloc[:,0])+np.median(data.iloc[:,0]))\n",
    "        plt.plot(np.array(predict)*stats.median_abs_deviation(data.iloc[:,0])+np.median(data.iloc[:,0]))            \n",
    "    plt.show()\n",
    "    '''\n",
    "    corrMatrix = pd.concat([Y,X],axis=1).corr().sort_values(kind=\"quicksort\", by=names[0], ascending=True,key=abs)\n",
    "    sns.heatmap(corrMatrix, annot=True)\n",
    "    plt.show()\n",
    "    \n",
    "    corrMatrix = pd.concat([Y,X],axis=1).pcorr().sort_values(kind=\"quicksort\", by=names[0], ascending=True,key=abs)\n",
    "    sns.heatmap(corrMatrix, annot=True)\n",
    "    plt.show()\n",
    "    \n",
    "    df_s = pd.concat([predict,Y[y],predict-Y[y]],axis=1).set_index(X.index)\n",
    "    df_s.columns = ['predict','actual','residual']\n",
    "    \n",
    "    def print_df_sort(interactValue):\n",
    "        sorted = df_s.sort_values(kind=\"quicksort\", by=interactValue, ascending=True)\n",
    "        plt.plot(sorted[interactValue])\n",
    "        plt.xticks(rotation = 45, size = 9)\n",
    "        plt.show()\n",
    "        sorted_ = pd.concat([sorted[interactValue],sorted[sorted.columns[~sorted.columns.isin([interactValue])]]],axis=1)\n",
    "        display(sorted_.style.background_gradient(cmap ='RdYlGn',axis=0))\n",
    "        \n",
    "    interactValue = widgets.Select(\n",
    "        options=df_s.columns,\n",
    "        value='residual',\n",
    "        # rows=10,\n",
    "        description='sort',\n",
    "        disabled=False\n",
    "        )\n",
    "    \n",
    "    interact(print_df_sort, interactValue=interactValue);\n",
    "    \n",
    "    print(\"mape:\",MAPE(Y[y],predict))\n",
    "    \n",
    "    linear_plot = Plot.LinearRegressionResidualPlot(X.values, Y.values)\n",
    "    lm = linear_plot.fit()\n",
    "    summary, diag_res = linear_plot.diagnostic_plots(lm)\n",
    "    #print(\"Summary of Regression\\n:{}\".format(summary))\n",
    "    print(\"Diagnostic Tests of Regression\\n:{}\".format(diag_res))\n",
    "    sns.set_theme(style=\"ticks\")\n",
    "    \n",
    "    temp = pd.concat([Y,X],axis=1)\n",
    "    temp.index = X.index\n",
    "    #temp['target']=temp[y]\n",
    "    sns.pairplot(temp,hue=y)\n",
    "    #return([results.summary(),temp])\n",
    "\n",
    "    modeldf = pd.read_html(results.summary().tables[1].as_html(),header=0,index_col=0)[0]\n",
    "\n",
    "    coef = modeldf['coef']\n",
    "    var_names = modeldf['coef'].index\n",
    "    print(var_names)\n",
    "    #print(coef.values>0)\n",
    "    above = list(X.columns[np.where(coef.values>=0)])\n",
    "    below = list(X.columns[np.where(coef.values<0)])\n",
    "\n",
    "    #nested functions (kind of like classes, get access to parent functions members).\n",
    "    def filter_df(x,y):\n",
    "\n",
    "        def print_df(aboveCenter,belowCenter,center):\n",
    "\n",
    "            data = df[[y,*x]].sort_values(kind=\"quicksort\", by=y, ascending=True)\n",
    "            \n",
    "            #abovePos = [i for i, item in enumerate(data.columns) if item in aboveMedian]\n",
    "            #belowPos = [i for i, item in enumerate(data.columns) if item in belowMedian]\n",
    "            \n",
    "            #i need to replace this with simply 0\n",
    "            \n",
    "            med = pd.DataFrame(np.median(data,axis=0)).T\n",
    "            means = pd.DataFrame(np.mean(data,axis=0)).T\n",
    "\n",
    "            med.columns = data.columns\n",
    "            \n",
    "            if(center):\n",
    "                centers = means\n",
    "\n",
    "            else:\n",
    "                centers = med\n",
    "            \n",
    "            filtered = data.copy()\n",
    "\n",
    "            #filters list against both sides of coefficient\n",
    "            filtered = filtered.iloc[pd.DataFrame(np.array(filtered[list(aboveCenter)])>np.array(centers[list(aboveCenter)])).replace(False,np.NaN).dropna().index]\n",
    "            #print(filtered)\n",
    "            filtered = filtered.iloc[pd.DataFrame(np.array(filtered[list(belowCenter)])<np.array(centers[list(belowCenter)])).replace(False,np.NaN).dropna().index]\n",
    "            #print(filtered)\n",
    "\n",
    "            #filtered = filtered.iloc[pd.DataFrame(np.array(filtered[list(aboveCenter)])>=0).replace(False,np.NaN).dropna().index]\n",
    "\n",
    "            #opposite = ([i for i, item in enumerate(data.columns) if item not in [filtered.index]])\n",
    "            oppositefilter = data.copy()\n",
    "\n",
    "            oppositefilter = oppositefilter.iloc[pd.DataFrame(np.array(oppositefilter[list(aboveCenter)])<np.array(centers[list(aboveCenter)])).replace(False,np.NaN).dropna().index]     \n",
    "            #print(oppositefilter)\n",
    "            oppositefilter = oppositefilter.iloc[pd.DataFrame(np.array(oppositefilter[list(belowCenter)])>np.array(centers[list(belowCenter)])).replace(False,np.NaN).dropna().index]   \n",
    "            #print(oppositefilter)\n",
    "            \n",
    "            #oppositefilter = filtered.iloc[pd.DataFrame(np.array(filtered[list(aboveCenter)])<0).replace(False,np.NaN).dropna().index]\n",
    "            #print(\"filtered:\",filtered.index)\n",
    "            #print(\"opposite:\",oppositefilter.index)\n",
    "            together = np.concatenate([filtered.index,oppositefilter.index])\n",
    "            #print(\"together\",together)\n",
    "            \n",
    "            neither = [i for i, item in enumerate(list(data.index)) if item not in together]\n",
    "            #print(\"neither\",neither)\n",
    "            \n",
    "            neitherfilter = data.copy()\n",
    "            neitherfilter = neitherfilter.iloc[neither]\n",
    "            #print(neitherfilter.index)\n",
    "\n",
    "            filtered_columns = np.concatenate([aboveCenter,belowCenter])\n",
    "\n",
    "            #quantiles_7num_9 = [0, .02,.09,.25,.5,.75,.91,.98, 1]\n",
    "            #quantiles_5num_7 = [0, .09,.25,.5,.75,.91, 1]\n",
    "            \n",
    "            quantiles_4num_6 = [0, .09,.25,.75,.91, 1]                        \n",
    "\n",
    "            threshold = widgets.FloatSlider(\n",
    "                min=0.02,\n",
    "                max=0.25,\n",
    "                value=0.125,\n",
    "                step=0.005,\n",
    "                description='Threshold:',\n",
    "                disabled=False,\n",
    "                continuous_update=False,\n",
    "                orientation='horizontal',\n",
    "                readout=True,\n",
    "                readout_format='f',\n",
    "            )     \n",
    "            \n",
    "            #debugging labels\n",
    "            #print(Y[y].sort_values())\n",
    "            \n",
    "            def printthreshold(threshold):\n",
    "                print(threshold)\n",
    "                #print(\"predict\")\n",
    "                #print(predict)\n",
    "                \n",
    "                #def return_quantile(data,quantiles):\n",
    "                    #quants = data.quantile(quantiles)\n",
    "\n",
    "                #for q in quants:\n",
    "                \n",
    "                #quantiles_3num_4 = [-3, .09,.91, 3]\n",
    "                \n",
    "                quantiles_3num_4 = [-3, threshold,1-threshold, 3]\n",
    "                #q_s_a_labels = return_quantile(data[y],quantiles_7num_9)\n",
    "                #q_labels = [1,2,3,4,5,6,7,8]\n",
    "                #q_labels = [1,2,3,4,5,6]\n",
    "                #q_labels = [1,2,3,4,5]\n",
    "                c_labels = [1,2,3]\n",
    "                '''\n",
    "                if(method=='mean'):\n",
    "                    raw_detransformed_values = set_['raw']\n",
    "                    raw_detransformed_values = raw_detransformed_values*np.std(scaled[y])+np.mean(scaled[y])\n",
    "                    \n",
    "                elif(method=='median'):\n",
    "                    raw_detransformed_values = set_['raw']\n",
    "                    raw_detransformed_values = raw_detransformed_values*np.std(scaled[y])+np.mean(scaled[y])#stats.median_abs_deviation(scaled['raw'])+np.median(scaled[y])\n",
    "                '''\n",
    "                raw_detransformed_values = set_['raw']*np.std(scaled[y])+np.mean(scaled[y])\n",
    "                #print(\"raw_detransformed_values\")\n",
    "                #print(raw_detransformed_values)\n",
    "                \n",
    "                q_s_a_labels = pd.cut(raw_detransformed_values, quantiles_3num_4, labels=c_labels, retbins=False, precision=3, duplicates='raise')\n",
    "                \n",
    "                #print(q_s_a_labels)\n",
    "                \n",
    "                #print(Y)\n",
    "                #print(set_['raw'])\n",
    "                #print(set_['raw'].describe())\n",
    "                print(np.std(set_['raw']))\n",
    "                print(np.mean(set_['raw']))\n",
    "                predicted_detransformed_values = predict*np.std(scaled[y])+np.mean(scaled[y])\n",
    "                \n",
    "                q_s_f_labels = pd.cut(predicted_detransformed_values, quantiles_3num_4, labels=c_labels, retbins=False, precision=3, duplicates='raise')\n",
    "                \n",
    "                \n",
    "                #print(predict)\n",
    "                #print(q_s_f_labels)\n",
    "                #q_s_f_labels = pd.qcut(predict, quantiles_4num_6, labels=q_labels, retbins=False, precision=3, duplicates='raise')\n",
    "\n",
    "                #x = np.arange(10)\n",
    "                #ys = [i+x+(i*x)**2 for i in range(10)]\n",
    "\n",
    "                q_s_a = data[y].quantile(quantiles_4num_6)\n",
    "                q_s_i = filtered[y].quantile(quantiles_4num_6)\n",
    "                q_s_o = oppositefilter[y].quantile(quantiles_4num_6)\n",
    "                q_s_n = neitherfilter[y].quantile(quantiles_4num_6)\n",
    "\n",
    "                colors = [\"red\", \"yellow\", \"purple\"]\n",
    "                x_vars = range(0,len(data.index))\n",
    "                y_vars = set_['raw']\n",
    "\n",
    "                colors = cm.rainbow(np.linspace(0, 1, len(data[y])))\n",
    "\n",
    "                color_indices = q_s_f_labels\n",
    "\n",
    "                colormap = matplotlib.colors.ListedColormap(colors)\n",
    "\n",
    "                #print(y)\n",
    "                #print(data[y])\n",
    "                #print(predict)\n",
    "                #print(Y)\n",
    "                print(method)\n",
    "                y_vars = Y[y]\n",
    "                '''\n",
    "                if(method=='mean'):                    \n",
    "                    y_vars = predict*np.std(data[y])+np.mean(data[y])\n",
    "                elif(method=='median'):\n",
    "                    #this is confusing.  I'm using standard scaling for y\n",
    "                    y_vars = predict*np.std(data[y])+np.mean(data[y])\n",
    "                    #y_vars = predict*stats.median_abs_deviation(data[y])+np.median(data[y])\n",
    "                '''\n",
    "                    \n",
    "                #print(\"y_vars\")\n",
    "                #print(y_vars)\n",
    "                    \n",
    "                display(\"color = predicted quantile\")\n",
    "                \n",
    "                plt.scatter(x_vars, y_vars.sort_values(kind=\"quicksort\", ascending=True).copy(), c=color_indices, cmap=colormap)\n",
    "                plt.show()\n",
    "\n",
    "                color_indices = q_s_a_labels\n",
    "\n",
    "                colormap = matplotlib.colors.ListedColormap(colors)\n",
    "\n",
    "                plt.scatter(x_vars, data[y].sort_values(kind=\"quicksort\", ascending=True), c=color_indices, cmap=colormap)                \n",
    "                plt.show()\n",
    "\n",
    "                data['States']=data.index\n",
    "\n",
    "                def printMap(mapSelect):\n",
    "\n",
    "                    print(mapSelect)\n",
    "\n",
    "                    if(mapSelect=='bifurcation'):\n",
    "\n",
    "                        data1 = pd.DataFrame(data[[y]]).assign(Location=0)[['Location',y]]\n",
    "                        data2 = pd.DataFrame(filtered[y]).assign(Location=1)[['Location',y]]\n",
    "                        data3 = pd.DataFrame(oppositefilter[y]).assign(Location=2)[['Location',y]]\n",
    "                        data4 = pd.DataFrame(neitherfilter[y]).assign(Location=3)[['Location',y]]\n",
    "                        #if(len(together)>0):\n",
    "                        data5 = pd.concat([data2,data3,data4],axis=0)#[['Location']]\n",
    "                        data5 = data5.sort_values(kind=\"quicksort\", by=y, ascending=True)                        \n",
    "                        display(type(data5['Location'][0]))\n",
    "\n",
    "                        #q_s_a_labels = data[y].quantile(quantiles_7num))\n",
    "\n",
    "                        display(\"red: in, yellow: out, purple: neither\")\n",
    "                        colormap = matplotlib.colors.ListedColormap(colors)\n",
    "                        color_indices = data5['Location']            \n",
    "\n",
    "                        plt.scatter(x_vars, y_vars.sort_values(kind=\"quicksort\", ascending=True), c=color_indices, cmap=colormap)\n",
    "                        plt.show()\n",
    "                        #print(pd.concat([Y[y],pd.DataFrame(predict).set_index(Y.index)],axis=1).sort_values(by=y,ascending=True))\n",
    "                        \n",
    "                        #print(data5['Location'])\n",
    "                        data['cluster'] = data5['Location']\n",
    "                        \n",
    "                        %matplotlib inline\n",
    "                        cdf = pd.concat([data1, data2, data3, data4])    \n",
    "                        mdf = pd.melt(cdf, id_vars=['Location'], var_name=['Group'])\n",
    "                        #print(mdf.head())\n",
    "\n",
    "                        sns.boxplot(x=\"Location\", y=\"value\", hue=\"Group\", data=mdf)    \n",
    "                        plt.show()                        \n",
    "\n",
    "                        #fig = mpf.figure(figsize=(10, 7), style=s)\n",
    "                        #fig = plt.figure(figsize=(800, 600))\n",
    "                        fig = plt.figure(figsize=plt.figaspect(2.))\n",
    "                        fig.suptitle('plots')\n",
    "                        #fig = Figure()\n",
    "                        #FigureCanvas(fig) # not needed in mpl >= 3.1\n",
    "                        ax1 = fig.add_subplot(6,2,1)\n",
    "                        ax2 = fig.add_subplot(6,2,2)\n",
    "                        ax3 = fig.add_subplot(6,2,3)\n",
    "                        ax4 = fig.add_subplot(6,2,4)\n",
    "                        ax5 = fig.add_subplot(6,2,5)\n",
    "                        ax6 = fig.add_subplot(6,2,6)\n",
    "\n",
    "                        display(\"all mapped against either group\")\n",
    "                        display(\"all mapped against neither group\")\n",
    "                        display(\"7 number ogive all mapped with in and out group\")\n",
    "                        display(\"7 number ogive all mapped against neither group\")\n",
    "                        ax1.hist(data[y])\n",
    "                        ax1.hist(filtered[y])\n",
    "                        ax1.hist(oppositefilter[y])\n",
    "                        ax2.hist(data[y])\n",
    "                        ax2.hist(neitherfilter[y])\n",
    "                        ax3.plot(data[y])\n",
    "                        ax3.tick_params(labelrotation=45)\n",
    "                        ax3.plot(filtered[y])\n",
    "                        ax3.plot(oppositefilter[y])\n",
    "                        #ax3.xticks(rotation = 45,size=8)\n",
    "                        ax4.plot(q_s_a)\n",
    "                        ax4.plot(q_s_i)\n",
    "                        ax4.plot(q_s_o)\n",
    "                        ax5.plot(data[y])\n",
    "                        ax5.plot(neitherfilter[y])\n",
    "                        ax5.tick_params(labelrotation=45)\n",
    "                        #ax5.xticks(rotation = 45,size=8)\n",
    "                        ax6.plot(q_s_a)\n",
    "                        ax6.plot(q_s_n)\n",
    "                        plt.show()        \n",
    "\n",
    "                        display(\"all group\")\n",
    "                        display(data.describe())\n",
    "\n",
    "                        display(\"in group\")\n",
    "                        sp = (st.ttest_ind(filtered[y],data[y],equal_var=False))\n",
    "                        display(sp.pvalue/2)\n",
    "                        #print(st.ttest_1samp(a=filtered[y],popmean=np.mean(data[y])))\n",
    "                        display(\"f/variance test:\",f_test(filtered[y],data[y]))\n",
    "                        #if(sp.pvalue/2<.05):\n",
    "                        #print(\"reject null hypothesis, B(filter)>A\")\n",
    "                        #df_ = len(filtered[y]) + len(data[y]) - 2\n",
    "                        #display(filtered.describe())\n",
    "                        display(read_data().loc[filtered.index].describe())\n",
    "                        #display(filtered)\n",
    "                        display(read_data().loc[filtered.index])\n",
    "\n",
    "                        display(\"out group\")\n",
    "                        sp = (st.ttest_ind(oppositefilter[y],data[y],equal_var=False))\n",
    "                        display(sp.pvalue/2)\n",
    "                        #print(st.ttest_1samp(a=oppositefilter[y],popmean=np.mean(data[y])))\n",
    "                        display(\"f/variance test:\",f_test(oppositefilter[y],data[y]))\n",
    "                        #if(sp.pvalue/2<.05):\n",
    "                            #print(\"reject null hypothesis, B(filter)>A\")\n",
    "                        #df_ = len(filtered[y]) + len(data[y]) - 2\n",
    "                        #display(oppositefilter.describe())\n",
    "                        display(read_data().loc[oppositefilter.index].describe())\n",
    "                        #display(oppositefilter)\n",
    "                        display(read_data().loc[oppositefilter.index])\n",
    "\n",
    "                        #return([filtered,oppositefilter])\n",
    "                        display(\"neither group\")\n",
    "                        sp = (st.ttest_ind(neitherfilter[y],data[y],equal_var=False))\n",
    "                        display(sp.pvalue/2)\n",
    "                        #print(st.ttest_1samp(a=neitherfilter[y],popmean=np.mean(data[y])))\n",
    "                        display(\"f/variance test:\",f_test(neitherfilter[y],data[y]))\n",
    "                        #display(neitherfilter.describe())\n",
    "                        display(read_data().loc[neitherfilter.index].describe()) \n",
    "\n",
    "                        neitherBox = widgets.Checkbox()\n",
    "\n",
    "                        def printNeither(neitherBox):\n",
    "                            if(neitherBox):\n",
    "                                 display(read_data().loc[neitherfilter.index])                            \n",
    "\n",
    "                        interact(printNeither,neitherBox=neitherBox)\n",
    "\n",
    "                    elif(mapSelect=='prediction'):\n",
    "\n",
    "                        #display(type(q_s_f_labels[0]))\n",
    "                        data['cluster'] = q_s_f_labels.astype('Int64')\n",
    "                        #print(data)\n",
    "                        data[[y,'cluster']].boxplot(by='cluster')\n",
    "                        plt.show()\n",
    "                        data[[y]].boxplot()\n",
    "                        plt.show()\n",
    "                        '''                        \n",
    "                        filtered = data[[y,'cluster']][data['cluster']==1][y]#.iloc[pd.DataFrame(np.array(filtered[list(belowCenter)])<np.array(centers[list(belowCenter)])).replace(False,np.NaN).dropna().index]\n",
    "                        print(filtered)\n",
    "\n",
    "                        oppositefilter = data[[y,'cluster']][data['cluster']==3][y]\n",
    "\n",
    "                        neitherfilter = data[[y,'cluster']][data['cluster']==2][y]\n",
    "                        #print(neitherfilter.index)    \n",
    "                        \n",
    "                        #%matplotlib inline\n",
    "                        #cdf = data    \n",
    "                        #mdf = pd.melt(cdf, id_vars=['cluster'], var_name=['Group'])\n",
    "                        #print(mdf.head())\n",
    "\n",
    "                        #sns.boxplot(x=\"cluster\", y=\"value\", hue=\"Group\", data=mdf)    \n",
    "                        #plt.show()      \n",
    "                        '''\n",
    "                        #q_s_a_labels = data[y].quantile(quantiles_7num))\n",
    "\n",
    "                        display(\"red: in, yellow: out, purple: neither\")\n",
    "                        colormap = matplotlib.colors.ListedColormap(colors)\n",
    "                        color_indices = data['cluster']            \n",
    "\n",
    "                        plt.scatter(x_vars, data[y], c=color_indices, cmap=colormap)\n",
    "                        plt.show()\n",
    "                                            \n",
    "                        for i in range(1,len(quantiles_3num_4)):\n",
    "                            if(i==1):\n",
    "                                print(\"lower\")\n",
    "                            elif(i==2):\n",
    "                                print(\"neither\")\n",
    "                            else:\n",
    "                                print(\"upper\")\n",
    "                            #display((df.loc[q_s_f_labels==i]).describe())\n",
    "                            display(read_data().loc[(df.loc[q_s_f_labels==i]).index].describe())\n",
    "                            #display(pd.concat([predict.loc[q_s_a_labels==i],df.loc[q_s_f_labels==i]],axis=1))\n",
    "                            display(read_data().loc[(df.loc[q_s_f_labels==i]).index].sort_values(kind=\"quicksort\", by=y, ascending=True))\n",
    "                            #display(df.loc[q_s_f_labels==i])\n",
    "                            #print(q_s_f_labels)\n",
    "                        \n",
    "                    else:\n",
    "                        data['cluster'] = q_s_a_labels.astype('Int64')                        \n",
    "                        data[[y,'cluster']].boxplot(by='cluster')\n",
    "                        \n",
    "                        plt.show()\n",
    "                        data[[y]].boxplot()\n",
    "                        plt.show()\n",
    "                        #df = pd.DataFrame(data, columns=list('ABCD'), index=index)\n",
    "                        #grouped = data.groupby(level='cluster')\n",
    "                        #grouped.boxplot(rot=45, fontsize=12, figsize=(8,10))  \n",
    "                        for i in range(1,len(quantiles_3num_4)):\n",
    "                            if(i==1):\n",
    "                                print(\"lower\")\n",
    "                            elif(i==2):\n",
    "                                print(\"neither\")\n",
    "                            else:\n",
    "                                print(\"upper\")\n",
    "                            display(read_data().loc[(df.loc[q_s_a_labels==i]).index].describe())\n",
    "                            #display(pd.concat([predict.loc[q_s_a_labels==i],df.loc[q_s_a_labels==i]],axis=1))\n",
    "                            #display(df.loc[q_s_a_labels==i])\n",
    "                            display(read_data().loc[(df.loc[q_s_a_labels==i]).index].sort_values(kind=\"quicksort\", by=y, ascending=True))\n",
    "                            #print(q_s_f_labels)\n",
    "                        #display(type(q_s_a_labels[0]))\n",
    "                        #print(q_s_a_labels)\n",
    "                        \n",
    "                        #q_s_a_labels.apply(lambda col:pd.Categorical(col).codes)\n",
    "\n",
    "                    state_vector = []\n",
    "                    #us_state_to_abbrev[[item for item in df.index]]\n",
    "                    for i in data.index:\n",
    "                        state_vector.append(us_state_to_abbrev.get(i, 0))\n",
    "\n",
    "                    with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "                        r_from_pd_df = ro.conversion.py2rpy(data)\n",
    "                        d=(r_f(r_from_pd_df))\n",
    "\n",
    "                    image = Image.open('C:/Users/User/Documents/wiki/wiki/dev/R/clusterMap.png')\n",
    "                    #image.show()\n",
    "                    display(image)\n",
    "\n",
    "                mapSelect = widgets.Select(\n",
    "                    options=['bifurcation','prediction','raw'],\n",
    "                    value='bifurcation',\n",
    "                    description='><coefficients class or quantiles',\n",
    "                    disabled=False\n",
    "                )\n",
    "\n",
    "                interact(printMap,mapSelect=mapSelect)                \n",
    "                #return( = [-3, .09,.91, 3])\n",
    "            interact(printthreshold,threshold=threshold)            \n",
    "            \n",
    "        display(\"used in bifurcation, i.e. class filter designations using means based on [significant] variables\")\n",
    "        aboveCenter = widgets.SelectMultiple(\n",
    "            options=names,\n",
    "            value=above,\n",
    "            description='AboveCenter',\n",
    "            disabled=False\n",
    "        )\n",
    "\n",
    "        belowCenter = widgets.SelectMultiple(\n",
    "            options=names,\n",
    "            value=below,\n",
    "            #options=df[list(x)].columns,\n",
    "            description='BelowCenter',\n",
    "            disabled=False\n",
    "        )\n",
    "\n",
    "        interact(print_df,aboveCenter=aboveCenter,belowCenter=belowCenter,center=center)\n",
    "\n",
    "    filter_df(x,y)\n",
    "    \n",
    "    return([results.summary()])\n",
    "\n",
    "def derive_xnames(y):\n",
    "    #print(y)\n",
    "    #print(type(df))\n",
    "    df=read_data()\n",
    "    center=widgets.Checkbox(\n",
    "        description='Center: [Checked: Mean, Unchecked: Median]',\n",
    "        value=True,\n",
    "        disabled=False,\n",
    "        indent=False)    \n",
    "    \n",
    "    x_ = widgets.SelectMultiple(\n",
    "        options=df.columns[~df.columns.isin([y])],\n",
    "        value=list(df.columns[~df.columns.isin([y])]),\n",
    "        disabled=False\n",
    "    )\n",
    "    autoremove = widgets.Checkbox()\n",
    "        \n",
    "    subset = interact(return_model_subset,x=x_,y=y,autoremove=True, center=center)\n",
    "    #subset = interact(return_model_vars,x=x_,y=y,autoremove=autoremove)\n",
    "\n",
    "    return(subset)\n",
    "\n",
    "\n",
    "y=widgets.Select(options=read_data().columns[0:-1],disabled=False)\n",
    "\n",
    "a=interact(derive_xnames,y=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe97594-4011-48fe-844c-44559386982d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff19916-6a97-4b0d-9779-f046d042f6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
